{"backend_state":"init","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"294.55px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"62ed9b","input":"","pos":97,"type":"cell"}
{"cell_type":"code","exec_count":1,"id":"749641","input":"# execute this cell to see scipy.optimize.minimize documentation\nIFrame(\n    \"https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize\",\n    width=900,\n    height=600)","metadata":{"code_folding":[0],"hidden":true},"output":{"0":{"ename":"NameError","evalue":"name 'IFrame' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3c9ffecb9411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# execute this cell to see scipy.optimize.minimize documentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m IFrame(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     height=600)\n","\u001b[0;31mNameError\u001b[0m: name 'IFrame' is not defined"]}},"pos":13,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"38da3f","input":"# add your code here, note you should be able to guess an initial value from the graph ...","metadata":{"hidden":true},"pos":26,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"be557d","input":"# execute this cell for video\nplay_video(\"ds775_lesson4-logistic-regression\")","output":{"0":{"data":{"text/html":"\n        <iframe\n            width=\"640\"\n            height=\"360\"\n            src=\"https://media.uwex.edu/content/ds/ds775_r19/ds775_lesson4-logistic-regression/index.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ","text/plain":"<IPython.lib.display.IFrame at 0x7f2434ba8c50>"},"exec_count":11,"output_type":"execute_result"}},"pos":32,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"a1d5b6","input":"# data from \nx_hours = np.array([\n    0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 1.75, 2.0, 2.25, 2.50, 2.75, 3.00, 3.25,\n    3.5, 4.0, 4.25, 4.5, 4.75, 5.0, 5.5\n])\ny_passed = np.array([0,0,0,0,0,0,1,0,1,0,1,0,1,0,1,1,1,1,1,1])","pos":36,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"270b80","input":"# graph of data and sigmoid\nb0 = -4.07771657\nb1 = 1.5046468\nhours_studied = np.linspace(0,6,101)\ndef sigmoid(x,intercept,slope):\n    return( 1.0 / (1.0 + np.exp( -(intercept + slope * x) ) ) )\nprob_passed = sigmoid(hours_studied, b0, b1)\n\nfig = plt.figure();\nfig.set_size_inches(6,3.5); # change size if needed on your display\nax = fig.add_subplot(111);\nax.scatter(x_hours, y_passed);\nax.plot(hours_studied, prob_passed);\nax.set_xlabel('hours studied');\nax.set_ylabel('passed');","metadata":{"code_folding":[]},"output":{"0":{"data":{"image/png":"29b0fded7fc78e72fa40134189e0b9b1dce65768","text/plain":"<Figure size 432x252 with 1 Axes>"},"exec_count":13,"metadata":{"image/png":{"height":234,"width":383}},"output_type":"execute_result"}},"pos":38,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"f083b5","input":"print(f\"A student who studies 4 hours has approximately {100 * sigmoid(4, b0, b1):3.1f}% chance of passing.\")","output":{"0":{"name":"stdout","output_type":"stream","text":"A student who studies 4 hours has approximately 87.4% chance of passing.\n"}},"pos":40,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"43a6ea","input":"def neg_log_loss( coef, *args):\n    b0 = coef[0]\n    b1 = coef[1]\n    x = args[0]\n    y = args[1]\n    yhat = b0 + b1 * x\n    p = 1.0/(1.0 + np.exp(-(b0 + b1*x)))\n    ll = sum( y*np.log(p)+(1-y)*np.log(1-p) )\n    return(-ll) # here's the minus sign!","metadata":{"code_folding":[]},"pos":43,"type":"cell"}
{"cell_type":"code","exec_count":16,"id":"e1fb87","input":"result = minimize(neg_log_loss,[0,0],args=(x_hours,y_passed))\nresult","output":{"0":{"data":{"text/plain":"      fun: 8.029878464344792\n hess_inv: array([[ 3.06213535, -1.02920658],\n       [-1.02920658,  0.3950086 ]])\n      jac: array([3.57627869e-07, 4.76837158e-07])\n  message: 'Optimization terminated successfully.'\n     nfev: 42\n      nit: 12\n     njev: 14\n   status: 0\n  success: True\n        x: array([-4.07771258,  1.50464515])"},"exec_count":16,"output_type":"execute_result"}},"pos":45,"type":"cell"}
{"cell_type":"code","exec_count":17,"id":"069ff0","input":"b0 = result.x[0]\nb1 = result.x[1]\nprint(f\"The maximum likelihood estimate for p(x) has intercept b0 = {b0:2.3f} and slope b1 = {b1:2.3f}\")","output":{"0":{"name":"stdout","output_type":"stream","text":"The maximum likelihood estimate for p(x) has intercept b0 = -4.078 and slope b1 = 1.505\n"}},"pos":46,"type":"cell"}
{"cell_type":"code","exec_count":18,"id":"2fcd79","input":"model = LogisticRegression(C=1.0e10,fit_intercept = True)\nmodel.fit(x_hours.reshape(-1,1), y_passed)\nb0 = model.intercept_[0]\nb1 = model.coef_[0][0]\nprint(f\"The maximum likelihood estimate for p(x) has intercept b0 = {b0:2.3f} and slope b1 = {b1:2.3f}\")","output":{"0":{"name":"stdout","output_type":"stream","text":"The maximum likelihood estimate for p(x) has intercept b0 = -4.078 and slope b1 = 1.505\n"}},"pos":48,"type":"cell"}
{"cell_type":"code","exec_count":19,"id":"9f6754","input":"# open to reveal graph code\ndef rastrigin_1D(x):\n    return (x**2 + 10 - 10 * np.cos(2 * np.pi * x))\n\nx = np.linspace(-5.12,5.12,201)\ny = rastrigin_1D(x)\n\nfig = plt.figure(figsize=(5,5)) # adjust figsize as needed for your display\nplt.plot(x,y)\nplt.xlabel('x');\nplt.ylabel('y');","metadata":{"code_folding":[0]},"output":{"0":{"data":{"image/png":"bbd094dfb43df609ac6eaf74d986702662c84472","text/plain":"<Figure size 360x360 with 1 Axes>"},"exec_count":19,"metadata":{"image/png":{"height":316,"width":325}},"output_type":"execute_result"}},"pos":51,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"547423","input":"# execute this cell for video\nplay_video(\"ds775_lesson4-optimization-basics\", w = 900, h = 600)","metadata":{"code_folding":[0],"hidden":true},"output":{"0":{"data":{"text/html":"\n        <iframe\n            width=\"900\"\n            height=\"600\"\n            src=\"https://media.uwex.edu/content/ds/ds775_r19/ds775_lesson4-optimization-basics/index.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ","text/plain":"<IPython.lib.display.IFrame at 0x7f243a69aef0>"},"exec_count":2,"output_type":"execute_result"}},"pos":4,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"e60b27","input":"# plot p(x) on [-10,10]\nx = np.linspace(-10,10,201)\np = lambda x:x**4 + 2*x**3 + 3*x**2 + 2*x + 1\nfig = plt.figure(figsize=(8,7)) # adjust figsize if needed\nplt.plot(x,p(x));\nplt.xlabel('x');\nplt.ylabel('y');","metadata":{"code_folding":[0],"hidden":true},"output":{"0":{"ename":"NameError","evalue":"name 'np' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-4b6600131f3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# plot p(x) on [-10,10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m201\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# adjust figsize if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}},"pos":17,"type":"cell"}
{"cell_type":"code","exec_count":20,"id":"96782c","input":"# Graph of Rastrigin with dimension n = 2\n%run scripts/rastrigin_2d.py","metadata":{"code_folding":[]},"output":{"0":{"data":{"iframe":"9fae8113077c599db39d154c4e6193211eeb5c3b"},"exec_count":20,"output_type":"execute_result"},"1":{"data":{"text/plain":"<Figure size 864x504 with 0 Axes>"},"exec_count":20,"output_type":"execute_result"}},"pos":52,"scrolled":true,"type":"cell"}
{"cell_type":"code","exec_count":21,"id":"da984d","input":"def rastrigin(x):\n    # pass a single vector of length n (=dim) to evaluate Rastrigin\n    return sum(x**2 + 10 - 10 * np.cos(2 * np.pi * x))\n\ndim = 10 # this determines the number of inputs to the Rastrigin function, there are 10 inputs or variables with dim=10\nnum_local_searches = 1000\nbest_value = 1.e10\nbounds = [(-5.12,5.12) for i in range(dim)] # make a list of tuples to give bounds for each of the dim = 10 variables\n\nfor i in range(num_local_searches):\n    x_initial = np.random.uniform(-5.12, 5.12, dim)\n    result = minimize(rastrigin,x_initial,bounds=bounds)\n    if result.fun < best_value:\n        best_value = result.fun\n        best_x = result.x\n        print(f\"New best value is {best_value:1.3f}\")\n\nprint(f\"\\nThe smallest value found is {best_value:4.3f}\")\nprint(f\"The location where the smallest values occurs is:\")\nfor i in range(dim):\n    print(f\"    x{i} = {best_x[i]:1.3f}\")","output":{"0":{"name":"stdout","output_type":"stream","text":"New best value is 47.758\nNew best value is 47.758\n"},"1":{"name":"stdout","output_type":"stream","text":"New best value is 22.884\n"},"2":{"name":"stdout","output_type":"stream","text":"New best value is 5.970\n"},"3":{"name":"stdout","output_type":"stream","text":"\nThe smallest value found is 5.970\nThe location where the smallest values occurs is:\n    x0 = 0.000\n    x1 = 0.000\n    x2 = -0.000\n    x3 = 0.995\n    x4 = 0.000\n    x5 = -0.995\n    x6 = -0.995\n    x7 = -0.995\n    x8 = 0.995\n    x9 = -0.995\n"}},"pos":54,"type":"cell"}
{"cell_type":"code","exec_count":22,"id":"a518bd","input":"# execute this cell for video\nplay_video(\"ds775_lesson4-logistic-traveling-salesman-problem\")","metadata":{"hidden":true},"output":{"0":{"data":{"text/html":"\n        <iframe\n            width=\"640\"\n            height=\"360\"\n            src=\"https://media.uwex.edu/content/ds/ds775_r19/ds775_lesson4-logistic-traveling-salesman-problem/index.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ","text/plain":"<IPython.lib.display.IFrame at 0x7f24141f9048>"},"exec_count":22,"output_type":"execute_result"}},"pos":73,"type":"cell"}
{"cell_type":"code","exec_count":23,"id":"acc6a4","input":"with open(\"data/Caps48.json\", \"r\") as tsp_data:\n    tsp = json.load(tsp_data)\ndistance_matrix = tsp[\"DistanceMatrix\"]\noptimal_tour = tsp[\"OptTour\"]\nopt_dist = tsp[\"OptDistance\"]/1000 # converted to kilometers\nxy = np.array(tsp[\"Coordinates\"])\n\ndef plot_tour(best_tour, xy_meters, best_dist, height, width):\n\n    meters_to_pxl = 0.0004374627441064968\n    intercept_x = 2.464\n    intercept_y = 1342.546\n    xy_pixels = np.zeros(xy_meters.shape)\n    xy_pixels[:,0] = meters_to_pxl * xy_meters[:,0] + intercept_x\n    xy_pixels[:,1] = -meters_to_pxl * xy_meters[:,1] + intercept_y\n\n    fig, ax = plt.subplots(1, 1, figsize=(height, width))\n    im = plt.imread('images/caps48.png')\n    implot = ax.imshow(im)\n    plt.setp(ax.get_xticklabels(), visible=False)\n    plt.setp(ax.get_yticklabels(), visible=False)\n    ax.tick_params(axis='both', which='both', length=0)\n\n    loop_tour = np.append(best_tour, best_tour[0])\n    ax.plot(xy_pixels[loop_tour, 0],\n            xy_pixels[loop_tour, 1],\n            c='b',\n            linewidth=1,\n            linestyle='-')\n    plt.title(f\"Best Distance {best_dist:.0f} km\")\n\nplot_tour(optimal_tour, xy, opt_dist, 9, 6) # change the height and width in the last two arguments as needed","metadata":{"code_folding":[]},"output":{"0":{"data":{"image/png":"09522351b64c3813d756188bc3f10d56ed3d9b48","text/plain":"<Figure size 648x432 with 1 Axes>"},"exec_count":23,"metadata":{"image/png":{"height":351,"width":516}},"output_type":"execute_result"}},"pos":76,"type":"cell"}
{"cell_type":"code","exec_count":24,"id":"7f2f84","input":"# define move, objective, and local search functions\n\ndef sub_tour_reversal(tour):\n    # reverse a random tour segment\n    num_cities = len(tour)\n    i, j = np.sort(np.random.choice(num_cities, 2, replace=False))\n    return np.concatenate((tour[0:i], tour[j:-num_cities + i - 1:-1],\n                              tour[j + 1:num_cities]))\n\ndef tour_distance(tour, dist_mat):\n    distance = dist_mat[tour[-1]][tour[0]]\n    for gene1, gene2 in zip(tour[0:-1], tour[1:]):\n        distance += dist_mat[gene1][gene2]\n    return distance/1000 # convert to kilometers\n\ndef random_reversal_search(dist_mat, max_no_improve):\n    num_cities = len(dist_mat)\n    # starts from a random tour\n    current_tour = np.random.permutation(np.arange(num_cities))\n    current_dist = tour_distance(current_tour, dist_mat)\n\n    # stop search if no better tour is found within max_no_improve iterations, can increase to eliminate crossovers\n    num_moves_no_improve = 0\n    iterations = 0\n    while (num_moves_no_improve < max_no_improve):\n        num_moves_no_improve += 1\n        iterations += 1  # just for tracking\n        new_tour = sub_tour_reversal(current_tour) # make a move\n        new_dist = tour_distance(new_tour, dist_mat)\n        if new_dist < current_dist: \n            num_moves_no_improve = 0\n            current_tour = new_tour # accept the move if it's an improvement\n            current_dist = new_dist\n    return current_tour, current_dist, iterations","pos":78,"type":"cell"}
{"cell_type":"code","exec_count":25,"id":"cebd04","input":"best_tour, best_dist, iterations = random_reversal_search(distance_matrix, 200)\n\nprint(f\"The minimum distance found is {best_dist:.0f} after {iterations:d} iterations\")\n\nplot_tour(best_tour, xy, best_dist, 9, 6)","metadata":{"code_folding":[]},"output":{"0":{"name":"stdout","output_type":"stream","text":"The minimum distance found is 19723 after 1838 iterations\n"},"1":{"data":{"image/png":"19c65fadcfba9b0b0d7fca9bd47cde2431e741a8","text/plain":"<Figure size 648x432 with 1 Axes>"},"exec_count":25,"metadata":{"image/png":{"height":351,"width":516}},"output_type":"execute_result"}},"pos":80,"type":"cell"}
{"cell_type":"code","exec_count":26,"id":"202739","input":"def sub_tour_reversal_ij(tour, i, j):\n    # reverse the segment from city i to city j\n    n = len(tour)\n    return (np.concatenate((tour[0:i], tour[j:-n + i - 1:-1], tour[j + 1:n])))\n\n# 2-opt local search for TSP\ndef two_opt(dist_mat):\n    num_cities = len(dist_mat)\n    current_tour = np.random.permutation(np.arange(num_cities))\n    current_dist = tour_distance(current_tour, dist_mat)\n    best_tour = current_tour\n    best_dist = current_dist\n\n    improvement = True\n    iterations = 0\n    while improvement:\n        improvement = False\n        for i in range(num_cities - 1):\n            for j in range(i + 1, num_cities):\n                iterations += 1\n                new_tour = sub_tour_reversal_ij(best_tour, i, j)\n                new_dist = tour_distance(new_tour, dist_mat)\n                if new_dist < best_dist:\n                    best_tour = new_tour\n                    best_dist = new_dist\n                    improvement = True\n    return best_tour, best_dist, iterations\n\nbest_tour, best_dist, iterations = two_opt(distance_matrix)\n\nprint(f\"The minimum distance found is {best_dist:.0f} km after {iterations:d} iterations\")\n\nplot_tour(best_tour, xy, best_dist, 9, 6)","metadata":{"hidden":true},"output":{"0":{"name":"stdout","output_type":"stream","text":"The minimum distance found is 18196 km after 4512 iterations\n"},"1":{"data":{"image/png":"de7a31217f476f730a2cc5463f81148f2c711c21","text/plain":"<Figure size 648x432 with 1 Axes>"},"exec_count":26,"metadata":{"image/png":{"height":351,"width":516}},"output_type":"execute_result"}},"pos":83,"type":"cell"}
{"cell_type":"code","exec_count":27,"id":"b4c228","input":"# load the data + random assignment\nnum_districts = 10\nmin_voters_in_district = 150\nmax_voters_in_district = 350\n\ndems = [152,81,75,34,62,38,48,74,98,66,83,86,72,28,112,45,93,72]\nreps = [62,59,83,52,87,87,69,49,62,72,75,82,83,53,98,82,68,98]\ncities = pd.DataFrame( data = {'dems':dems, 'reps':reps})\n\n# assign = np.random.randint(low=0,high=num_districts,size = 18)\nassign = np.array([4, 3, 1, 9, 4, 0, 2, 8, 0, 9, 8, 0, 0, 0, 8, 7, 3, 6])\nassign","metadata":{"code_folding":[]},"output":{"0":{"data":{"text/plain":"array([4, 3, 1, 9, 4, 0, 2, 8, 0, 9, 8, 0, 0, 0, 8, 7, 3, 6])"},"exec_count":27,"output_type":"execute_result"}},"pos":88,"type":"cell"}
{"cell_type":"code","exec_count":28,"id":"c2a2be","input":"def summarize_districts(assign, cities):\n    reps = np.zeros(num_districts, dtype=np.int32)\n    dems = np.zeros(num_districts, dtype=np.int32)\n    df = cities.groupby(assign).sum()\n    reps[df.index] = df['reps']\n    dems[df.index] = df['dems']\n    total = reps + dems\n    delta = np.minimum(np.maximum(total, min_voters_in_district),\n                       max_voters_in_district) - total\n    rep_win = reps > dems\n    dict = {\n        'reps': reps,\n        'dems': dems,\n        'total': total,\n        'rep_win': rep_win\n    }\n    return (pd.DataFrame(data=dict))\n\nsummarize_districts(assign, cities)","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reps</th>\n      <th>dems</th>\n      <th>total</th>\n      <th>rep_win</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>367</td>\n      <td>322</td>\n      <td>689</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>83</td>\n      <td>75</td>\n      <td>158</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>69</td>\n      <td>48</td>\n      <td>117</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>127</td>\n      <td>174</td>\n      <td>301</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>149</td>\n      <td>214</td>\n      <td>363</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>98</td>\n      <td>72</td>\n      <td>170</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>82</td>\n      <td>45</td>\n      <td>127</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>222</td>\n      <td>269</td>\n      <td>491</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>124</td>\n      <td>100</td>\n      <td>224</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   reps  dems  total  rep_win\n0   367   322    689     True\n1    83    75    158     True\n2    69    48    117     True\n3   127   174    301    False\n4   149   214    363    False\n5     0     0      0    False\n6    98    72    170     True\n7    82    45    127     True\n8   222   269    491    False\n9   124   100    224     True"},"exec_count":28,"output_type":"execute_result"}},"pos":90,"type":"cell"}
{"cell_type":"code","exec_count":29,"id":"e35eb1","input":"def fitness_districts(assign, cities, num_districts):\n    df = cities.groupby(assign).sum()\n    fitness = sum( df['reps'] > df['dems'] )\n    total_voters = np.zeros(num_districts,dtype=np.int32)\n    total_voters[df.index] = df.sum(axis=1)\n    fitness -= np.abs(np.minimum(np.maximum(total_voters,150),350)-total_voters).sum()\n    return (fitness)\n\nfitness_districts(assign, cities, num_districts)","output":{"0":{"data":{"text/plain":"-693"},"exec_count":29,"output_type":"execute_result"}},"pos":92,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"5b6dd7","input":"# execute for local search\nresult = minimize(p,-2)\nresult","metadata":{"code_folding":[],"hidden":true},"output":{"0":{"ename":"NameError","evalue":"name 'minimize' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-44c095de4335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# execute for local search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'minimize' is not defined"]}},"pos":21,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"dfd775","input":"# unfold to see Pyomo solution for Wyndor Quadratic Program\nimport pyomo.environ as pyo\n\n# Concrete Model\nmodel = pyo.ConcreteModel(name=\"Wyndor\")\n\nproducts = ['drs', 'wdw']\n\nbounds_dict = {'drs': (0, 4), 'wdw': (0, 6)}\n\n\ndef bounds_rule(model, product):\n    return (bounds_dict[product])\n\n\nmodel.x = pyo.Var(products, domain=pyo.Reals, bounds=bounds_rule)\n\n# Objective\nmodel.profit = pyo.Objective(expr=126.0 * model.x['drs'] -\n                         9.0 * model.x['drs']**2 + 182.0 * model.x['wdw'] -\n                         13.0 * model.x['wdw']**2.0,\n                         sense=pyo.maximize)\n\n# Constraints\nmodel.Constraint3 = pyo.Constraint(\n    expr=3.0 * model.x['drs'] + 2.0 * model.x['wdw'] <= 18)\n\n# Solve\nsolver = pyo.SolverFactory('ipopt')\nsolver.solve(model)\n\n# display(model)\n\n# display solution\nimport babel.numbers as numbers  # needed to display as currency\nprint(f\"Profit = ${1000*model.profit():,.2f}\")\n\nprint(f\"Batches of Doors = {model.x['drs']():1.2f}\")\nprint(f\"Batches of Windows = {model.x['wdw']():1.2f}\")","metadata":{"code_folding":[],"hidden":true},"output":{"0":{"name":"stdout","output_type":"stream","text":"Profit = $857,000.00\nBatches of Doors = 2.67\nBatches of Windows = 5.00\n"}},"pos":9,"type":"cell"}
{"cell_type":"code","exec_count":30,"id":"d6df7d","input":"def move_one_city(assign, num_districts):\n    num_cities = assign.shape[0] # or len(assign)\n    new_assign = assign.copy()\n    switch_city = np.random.randint(num_cities) # which city to assign new random district\n    while new_assign[switch_city] == assign[switch_city]: # loops until new and old are different\n        new_assign[ switch_city] = np.random.randint(num_districts)\n    return new_assign","pos":94,"type":"cell"}
{"cell_type":"code","exec_count":31,"id":"b9722c","input":"def sub_tour_reversal(tour):\n    # reverse a random tour segment\n    num_cities = len(tour)\n    i, j = np.sort(np.random.choice(num_cities, 2, replace=False))\n    return np.concatenate((tour[0:i], tour[j:-num_cities + i - 1:-1],\n                              tour[j + 1:num_cities]))\n\ndef tour_distance(tour, dist_mat):\n    distance = dist_mat[tour[-1]][tour[0]]\n    for gene1, gene2 in zip(tour[0:-1], tour[1:]):\n        distance += dist_mat[gene1][gene2]\n    return distance/1000 # convert to kilometers","pos":101,"type":"cell"}
{"cell_type":"code","exec_count":32,"id":"53c35e","input":"from locsearch import LocalSearcher\n\nclass TravelingSalesmanProblem(LocalSearcher):\n    \"\"\"\n    Test local search with a traveling salesman problem\n    \"\"\"\n    \n    # pass extra data (the distance matrix) into the constructor\n    def __init__(self, state, distance_matrix):\n        self.distance_matrix = distance_matrix\n        super(TravelingSalesmanProblem, self).__init__(state)  # important!\n        \n    def move(self):\n        self.state = sub_tour_reversal(self.state)\n        \n    def objective(self):\n        return tour_distance(self.state,self.distance_matrix)","pos":103,"type":"cell"}
{"cell_type":"code","exec_count":33,"id":"b9cc35","input":"# read problem data\nwith open(\"data/Caps48.json\", \"r\") as tsp_data:\n    tsp = json.load(tsp_data)\ndistance_matrix = tsp[\"DistanceMatrix\"]\n\n# create initial state\nnum_cities = len(distance_matrix)\ninit_tour = np.random.permutation(np.arange(num_cities))\n\n# create a tsp object of the TravelingSalesmanProblem class\ntsp = TravelingSalesmanProblem(init_tour, distance_matrix)\n\n# call the local search method in our object to do the search\nbest_tour, best_dist = tsp.localsearch()","output":{"0":{"name":"stdout","output_type":"stream","text":"\n Obj Fun Val | Iterations\n    57262.09 | 100\n    43962.28 | 200\n    36884.89 | 300\n    34256.60 | 400\n"},"1":{"name":"stdout","output_type":"stream","text":"    33200.83 | 500\n    29033.94 | 600\n    27141.05 | 700\n    25036.34 | 800\n    24594.89 | 900\n    23458.99 | 1000\n    23166.66 | 1100\n    22928.67 | 1200\n    22928.67 | 1300\n    22704.59 | 1400\n    22244.78 | 1500\n    21803.62 | 1600\n    21504.67 | 1700\n    21454.77 | 1800\n    21454.77 | 1900\n    21332.60 | 2000\n    20379.87 | 2100\n    19851.51 | 2200\n    19851.51 | 2300\n    19647.83 | 2400\n    19572.42 | 2500\n"},"2":{"name":"stdout","output_type":"stream","text":"    19226.96 | 2600\n    19226.96 | 2700\n    19226.96 | 2800\n    19081.39 | 2900\n    19081.39 | 3000\n    19009.72 | 3100\n    18921.14 | 3200\n    18921.14 | 3300\n    18921.14 | 3400\n    18921.14 | 3500\n    18784.01 | 3600\n    18784.01 | 3700\n    18736.78 | 3800\n    18736.78 | 3900\n    18736.78 | 4000\n    18736.78 | 4100\n    18736.78 | 4200\n    18736.78 | 4300\n    18736.78 | 4400\n    18736.78 | 4500\n    18656.03 | 4600\n    18656.03 | 4700\n    18656.03 | 4800\n    18656.03 | 4900\n    18656.03 | 5000\n"},"3":{"name":"stdout","output_type":"stream","text":"    18656.03 | 5100\n    18656.03 | 5200\n    18656.03 | 5300\n    18656.03 | 5400\n    18656.03 | 5500\n    18656.03 | 5566\n"}},"pos":105,"type":"cell"}
{"cell_type":"code","exec_count":34,"id":"cb4540","input":"# read problem data\nwith open(\"data/Caps48.json\", \"r\") as tsp_data:\n    tsp = json.load(tsp_data)\ndistance_matrix = tsp[\"DistanceMatrix\"]\n\n# create initial state\nnum_cities = len(distance_matrix)\ninit_tour = np.random.permutation(np.arange(num_cities))\n\n# create a tsp object of the TravelingSalesmanProblem class\ntsp = TravelingSalesmanProblem(init_tour, distance_matrix)\n\n# override default settings\ntsp.max_no_improve = 300\ntsp.update_iter = 200\n\n# call the local search method in our object to do the search\nbest_tour, best_dist = tsp.localsearch()","output":{"0":{"name":"stdout","output_type":"stream","text":"\n Obj Fun Val | Iterations\n    44587.58 | 200\n    32764.89 | 400\n    29330.37 | 600\n    26162.07 | 800\n    23927.36 | 1000\n    22629.76 | 1200\n    21270.44 | 1400\n"},"1":{"name":"stdout","output_type":"stream","text":"    20202.82 | 1600\n    19784.14 | 1800\n    19784.14 | 1946\n"}},"pos":107,"type":"cell"}
{"cell_type":"code","exec_count":35,"id":"fe7c03","input":"def sub_tour_reversal(tour):\n    # reverse a random tour segment\n    num_cities = len(tour)\n    i, j = np.sort(np.random.choice(num_cities, 2, replace=False))\n    return np.concatenate((tour[0:i], tour[j:-num_cities + i - 1:-1],\n                              tour[j + 1:num_cities]))\n\ndef tour_distance(tour, dist_mat):\n    distance = dist_mat[tour[-1]][tour[0]]\n    for gene1, gene2 in zip(tour[0:-1], tour[1:]):\n        distance += dist_mat[gene1][gene2]\n    return distance/1000 # convert to kilometers\n\nfrom locsearch import LocalSearcher\n\nclass TravelingSalesmanProblem(LocalSearcher):\n    \"\"\"\n    Test local search with a traveling salesman problem\n    \"\"\"\n    \n    # pass extra data (the distance matrix) into the constructor\n    def __init__(self, state, distance_matrix):\n        self.distance_matrix = distance_matrix\n        super(TravelingSalesmanProblem, self).__init__(state)  # important!\n        \n    def move(self):\n        self.state = sub_tour_reversal(self.state)\n        \n    def objective(self):\n        return tour_distance(self.state,self.distance_matrix)\n    \n# read problem data\nimport json\nwith open(\"data/Caps48.json\", \"r\") as tsp_data:\n    tsp = json.load(tsp_data)\ndistance_matrix = tsp[\"DistanceMatrix\"]\n\n# create initial state\nnum_cities = len(distance_matrix)\ninit_tour = np.random.permutation(np.arange(num_cities))\n\n# create a tsp object of the TravelingSalesmanProblem class\ntsp = TravelingSalesmanProblem(init_tour, distance_matrix)\n\n# uncomment to override default search and output settings\n# tsp.max_no_improve = 300\ntsp.update_iter = 500\n\n# call the local search method in our object to do the search\nbest_tour, best_dist = tsp.localsearch()","output":{"0":{"name":"stdout","output_type":"stream","text":"\n Obj Fun Val | Iterations\n    28759.22 | 500\n    22194.40 | 1000\n    19687.03 | 1500\n"},"1":{"name":"stdout","output_type":"stream","text":"    19517.48 | 2000\n    19384.15 | 2500\n"},"2":{"name":"stdout","output_type":"stream","text":"    19384.15 | 3000\n"},"3":{"name":"stdout","output_type":"stream","text":"    19201.83 | 3500\n    18977.89 | 4000\n    18834.35 | 4500\n"},"4":{"name":"stdout","output_type":"stream","text":"    18515.99 | 5000\n    18515.99 | 5500\n"},"5":{"name":"stdout","output_type":"stream","text":"    18515.99 | 5853\n"}},"pos":109,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"417825","input":"print(f\"The minimum value is {result.fun:0.4f} and occurs at x = {result.x[0]:0.4f}\")","metadata":{"hidden":true},"output":{"0":{"ename":"NameError","evalue":"name 'result' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-2ec6dee2c2e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The minimum value is {result.fun:0.4f} and occurs at x = {result.x[0]:0.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"]}},"pos":22,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"a39f17","input":"# EXECUTE FIRST\n\n# computational imports\nimport numpy as np\nimport pandas as pd\nfrom scipy.optimize import minimize\nfrom sklearn.linear_model import LogisticRegression\nimport json\n# plotting imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n# for reading files from urls\nimport urllib.request\n# display imports\nfrom IPython.display import display, IFrame\nfrom IPython.core.display import HTML\n\n# for playing videos, customize height and width if desired\ndef play_video(vid_name, w = 640, h = 360):\n    vid_path = \"https://media.uwex.edu/content/ds/ds775_r19/\"\n    return IFrame( vid_path + vid_name + \"/index.html\", width = w, height = h )\n\n# import notebook styling for tables and width etc.\nresponse = urllib.request.urlopen('https://raw.githubusercontent.com/DataScienceUWL/DS775v2/master/ds755.css')\nHTML(response.read().decode(\"utf-8\"));","metadata":{"code_folding":[0]},"pos":0,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"c8c7c0","input":"# plot p(x) on [-3,3]\nx = np.linspace(-3,3,201)\np = lambda x:x**4 + 2*x**3 + 3*x**2 + 2*x + 1\nfig = plt.figure(figsize=(8,7))\nplt.plot(x,p(x));\nplt.xlabel('x');\nplt.ylabel('y');","metadata":{"code_folding":[0],"hidden":true},"output":{"0":{"data":{"image/png":"122d4724cbffde02093505edfd434f843a053017","text/plain":"<Figure size 576x504 with 1 Axes>"},"exec_count":6,"metadata":{"image/png":{"height":424,"width":497}},"output_type":"execute_result"}},"pos":19,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"643d28","input":"# graph of profit function\nx = np.linspace(0,250,201) # 201 points between 0 and 250\nP = lambda x:-0.008*x**2 + 3.1*x - 80 # lambda is for writing one line functions\nfig = plt.figure(figsize=(8,7));\nplt.plot(x,P(x));\nplt.xlabel('apartments');\nplt.ylabel('profit (\\$ thousands)');","metadata":{"code_folding":[0],"hidden":true},"output":{"0":{"data":{"image/png":"2e0d3b0fc3f0924c71a11fd627be84a0323e878c","text/plain":"<Figure size 576x504 with 1 Axes>"},"exec_count":9,"metadata":{"image/png":{"height":424,"width":498}},"output_type":"execute_result"}},"pos":25,"type":"cell"}
{"cell_type":"markdown","id":"015c3b","input":"**Note: dimensions or `dim` is the number of input variables to the objective function.**\n\n### *Self-Assessment: Rastrigin with dim = 3, 4*","pos":55,"type":"cell"}
{"cell_type":"markdown","id":"02a151","input":"The overall \"U\" shape is not surprising since for polynomials the behavior for large values of $x$ is determined by the highest degree term which is, in this case, $x^4$.  It appears that there is a minimum or minima close to the origin.  Let's zoom in a bit to see what we can:","metadata":{"hidden":true},"pos":18,"type":"cell"}
{"cell_type":"markdown","id":"07b7eb","input":"This example is based on textbook problem 13.10-6.  The details of the objective function aren't important, this is intended to serve as another example of discrete optimization.\n\nBecause of population growth, the state of Washington has been given an additional seat in the House of Representatives, making a total of 10. The state legislature, which is currently controlled by the Republicans, needs to develop a plan for redistricting the state. There are 18 major cities in the state of Washington that need to be assigned to one of the 10 congressional districts. The table below gives the numbers of registered Democrats and registered Republicans in each city. Each district must contain between 150,000 and 350,000 of these registered voters. Assign each city to one of the 10 congressional districts in order to maximize the number of districts that have more registered Republicans than registered Democrats.\n\n<img src=\"images/gerrymandering.png\" width=\"300\">\n\nWe'll provide the data and objective function below.","pos":86,"type":"cell"}
{"cell_type":"markdown","id":"09d744","input":"### Find the model with `minimize`","pos":42,"type":"cell"}
{"cell_type":"markdown","id":"0c3ccf","input":"Start with a random state and move to a nearby state by changing one of the city assignments randomly.  You don't have to check for feasibility of each new state, just accept the move if you get a larger value of the fitness function.  Repeat until no progress is made for 1000 moves.  Your local search should be inside of a function with inputs the cities and the initial assignment.  The output should be the optimized assignment and the value of the fitness function.  \n\nNow write a loop that does 100 local searches.  Make sure the final, best solution is feasible.  What is the maximum number of districts that Republicans win?","pos":96,"type":"cell"}
{"cell_type":"markdown","id":"0d88d2","input":"## An Object-Oriented Approach to Local Search","pos":98,"type":"cell"}
{"cell_type":"markdown","id":"0f7d97","input":"Your answer shouldn't be an integer.  We could use discrete optimization and only optimize integer numbers of apartments, but it will usually be more computationally intensive.  Instead we're using a continuous variable to get an approximation to the discrete problem, this is called **relaxation** (we've relaxed the integer variable condition).  So what whole number of apartments should you rent?  Why? ","metadata":{"hidden":true},"pos":27,"type":"cell"}
{"cell_type":"markdown","id":"102525","input":"<font size=18>Lesson 04: Quadratic Programming and Local Optimization</font>","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"11db09","input":"*Note:  It isn't important to understand the details of logistic regression for this class, but the text in this cell gives a bit of background.*\n\nWhere do those values for the slope and intercept come from?  To obtain those we find the values of $b_0$ and $b_1$ that maximize the likelihood function:\n$$ L(b_0,b_1) = \\prod_{i=1}^{n} p(x_i)^{y_i} (1-p(x_i))^{(1-y_i)}$$\nwhere $(x_i,y_i)$ are the data pairs for each student and $p(x) = \\displaystyle \\frac{1}{1 + e^{-(b_0 + b_1 x)}}$ is the sigmoid function.  By maximizing the likelihood function we are maximizing the probability that this model produced the observed data.  Note that the $\\prod$ symbol means to take the product of the values, like $\\sum$ means to take the sum.\n\nIn practice, maximizing a product can lead to numerical difficulties, so we instead maximize the log-likelihood function found by taking the logarithm of $L(b_0,b_1)$ to get:\n$$LL(b_0, b_1) = \\sum_{i = 1}^{n} \\left[ y_i \\log( p(x_i) ) + (1-y_i) \\log(1-p(x_i)) \\right].$$\n\nNow we need to find $b_0$ and $b_1$ to maximize this.  The log-likelihood function turns out to be concave so that ascending from any starting point will lead to the global maximum.  \n\nBecause we will use the `minimize` function from `scipy.optimize` to find the maximum log-likelihood we'll minimize the negative log-likelihood:","pos":41,"type":"cell"}
{"cell_type":"markdown","id":"1250f3","input":"The function $f(x) = x^5 - x^4 - 18 x^3 + 16 x^2 + 32 x - 2$ for $-4 \\leq x \\leq 3.6$ appears in the video \"Gradient Descent and Local Minima\" above.  Plot the function on the given interval.  Use the graph to guess where the local maxima and minima are.  Now use minimize from scipy.optimize to find the $x$ and $y$ coordinates of all the extrema.  You can add bounds to the minimize call like this:\n\n```\nminimize(f,x0,bounds=[(-4,3.6)])\n```\nLocal extrema only occur on the interior of the interval and not at the endpoints.","metadata":{"hidden":true},"pos":29,"type":"cell"}
{"cell_type":"markdown","id":"12a957","input":"## Minimize from scipy.optimize","metadata":{"heading_collapsed":true},"pos":12,"type":"cell"}
{"cell_type":"markdown","id":"149a6b","input":"We'll use Pyomo to solve the quadratic variation of the Wyndor problem illustrated in Figure 13.6 on page 554.\n\n<img src=\"images/wyndor_quad.png\" width=\"600\">\n\nThis kind of profit function occurs when the price depends on demand.  We'll use a concrete model formulation for simplicity.  Note, the Pyomo package `minimize` conflicts with the `minimize` from `scipy.optimize` we're using elsewhere in this notebook, so we'll import `pyomo` a bit differently here than usual.  Alternately we could re-import `minimize` from `scipy.optimize` after we're done with Pyomo.","metadata":{"hidden":true},"pos":8,"type":"cell"}
{"cell_type":"markdown","id":"1cbe9d","input":"While there are many options here, the defaults will serve well for our purposes.  The `method` specifies a variety of different numerical algorithms for local search.  We'll use `BFGS` for unbounded problems and `L-BFGS-B` for problems with bounds.  You shouldn't have to specify that choice as those are the defaults.  The BFGS methods are robust algorithms and are known as quasi-Newton methods.  What this means is that they approximate the shape of the objective function near the current point by approximating the derivatives (slopes and curvature) of the function and that shape information is used to produce an improved search point. \n\nOne of the things to pay attention to here is how we have to write our objective functions so that they can be passed to the `minimize` function.","metadata":{"hidden":true},"pos":14,"type":"cell"}
{"cell_type":"markdown","id":"1d0ba0","input":"First we import the `LocalSearcher` class from the `locsearch` package.\n```\nfrom locsearch import LocalSearcher\n```\n\nIf you want to see all the details have a look at `localsearch/ls.py` in the same directory as this notebook.\n\nNow we define a new class called `TravelingSalesmanProblem` that inherits from the `LocalSearcher` class:\n\n```\nclass TravelingSalesmanProblem(LocalSearcher):\n    \"\"\"\n    Test local search with a traveling salesman problem\n    \"\"\"\n```\n\nFor the TSP we'll need to provide the distance matrix as an extra input to the objective function.  To do this we need to tell the `__init__` constructor that we're going to input an extra argument in addition to the initial state. The `super()` command tells Python that this is in addition to `__init__` constructor that is inherited from the parent class `LocalSearcher`:\n```\n    # pass extra data (the distance matrix) into the constructor\n    def __init__(self, state, distance_matrix):\n        self.distance_matrix = distance_matrix\n        super(TravelingSalesmanProblem, self).__init__(state)  # important!\n```\nIt's import to include the `super()` command and also to add the additional arguments after `self` and `state` in the arguments to `__init__`.  If you don't need to pass arguments other than `state` to your objective function then you can leave out the whole `__init__` constructor from your class definition.\n\nNow we have to define the `move()` method.  The parent class has a `move()` method that is inherited by our `TravelingSalesmanProblem` class, but it doesn't actually do anything.  To create our `move()` method we simply call our `sub_tour_reversal()` to create a new tour.  \n```\n    def move(self):\n        self.state = sub_tour_reversal(self.state)\n```\n\nYou could also include all the code to compute the new tour into the `move()` method, but it's easier to call the `sub_tour_reversal()` function we defined already.\n\nFinally, we have to define our objective function.  There is an `objective()` method inherited from the parent `LocalSearcher` class, but it doesn't do anything.  To build our own we just call the already defined `tour_distance()` function.  Notice that `tour_distance()` needs two arguments:  a tour which is stored in `self.state` and the distance matrix which is stored in `self.distance_matrix` because we told our `__init__` constructor to add that to our object.\n\n```\n    def objective(self):\n        return tour_distance(self.state,self.distance_matrix)\n```\n\nSo far we haven't actually created an object of the `TravelingSalesmanProblem` class, instead we've just defined the class.\n\nThe next steps are to read the problem data, create an initial state, create the TSP object, and do the optimization.  These steps are shown in the code in the next cell.","pos":104,"type":"cell"}
{"cell_type":"markdown","id":"220074","input":"For the Rastrigin function write a while loop that runs until the global minimum value is found ($|\\mbox{best_val}|<0.01$) and track the number of iterations. Use a for loop to repeat this three times until your code is debugged.  After your code is working, repeat the process 100 times and report the average number of searches until the global minimum is found when $n=1,2,3$.  Are these numbers in approximate agreement with with the estimated numbers $10.24^n$ (they very likely won't be all that close, but how is the overall trend)?","metadata":{"hidden":true},"pos":62,"type":"cell"}
{"cell_type":"markdown","id":"249160","input":"**Execute cell below to do the local search.  Repeat a few times to see how each local search results in a different tour corresponding to a different local minimum.**","pos":79,"type":"cell"}
{"cell_type":"markdown","id":"26b6b6","input":"## The Basics of Local Search","pos":67,"type":"cell"}
{"cell_type":"markdown","id":"275528","input":"# Quadratic Programming","metadata":{"heading_collapsed":true},"pos":5,"type":"cell"}
{"cell_type":"markdown","id":"2c98e3","input":"# Local Search - Discrete Variables","pos":65,"type":"cell"}
{"cell_type":"markdown","id":"3e331b","input":"## Gerrymandering Example","pos":85,"type":"cell"}
{"cell_type":"markdown","id":"41a197","input":"We'll have a look at an algorithm called \"2-opt\" that was proposed by Croes in 1958.  We won't focus on it too much since the idea doesn't really extend to other problems.  The main idea  is to reverse segments that cross over themselves to remove the cross over.  We loop repeatedly over all the possible reversals until there are no more cross overs.  Here is some Python to do 2-opt:","metadata":{"hidden":true},"pos":82,"type":"cell"}
{"cell_type":"markdown","id":"42bb30","input":"2-opt is can use fewer iterations to find a reasonable tour (local minimum) than does our local search with random segment reversals.  2-opt guarantees that there are no \"crossovers\" in the final tour.  In the next lesson we'll try using 2-opt to find starting points for a global search algorithm.","metadata":{"hidden":true},"pos":84,"type":"cell"}
{"cell_type":"markdown","id":"431787","input":"Work your way through the embedded storybook below to learn some basic ideas about optimization.  This material complements the material in the textbook.  The graphs and demos in Slides 9-11 are available in the separate file Storybook_Graphs_04.ipynb.","metadata":{"hidden":true},"pos":3,"type":"cell"}
{"cell_type":"markdown","id":"44b19d","input":"For the objective function, `fitness_districts` we count the number of districts won by republicans.  Instead of checking each potential solution to see if it's feasible (between 150 and 350 voters in each district) we subtract the total number of thousands by which each district is out of bounds.  This approach to optimization is called a **penalty function method**.  It doesn't prevent infeasible solutions, but it strongly penalizes them so that when the function is optimized the solution generally will be feasible.  Note that in the table above we have several districts that too many or two few voters, when we compute the fitness of that assignment to districts it is negative because of the penalty term.","pos":91,"type":"cell"}
{"cell_type":"markdown","id":"469f6b","input":"Most machine learning algorithms are driven by optimization.  Usually we want to minimize a loss function which measures the difference between the model predictions and the observed data.  Neural network training uses a version of the gradient descent algorithm to optimize the weights in the network.  Here we'll show how to fit a logistic regression model by maximizing a function.\n\nIn simple logistic regression we try to predict the value of the label $y$, which can be 0 or 1, for each value of a continuous predictor variable $x$.  In particular, the conditional probability that $y=1$ given the current value of $x$ is modeled by a sigmoid function (\"s\" curve) $$p(x) = \\frac{1}{1 + e^{-(b_0 + b_1 x)}}.$$\n\nFor example, the more hours a student studies to prepare for an exam, the higher the probability that they will pass the test.  Shown below is some data.  For each student we have the number of hours they studied and whether or not they passed the exam (1 for passed, 0 for failed).  This example data comes from the <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\">Wikipedia article on Logistic Regresssion</a>.","pos":34,"type":"cell"}
{"cell_type":"markdown","id":"4fd60a","input":"### Setup for Logistic Regression","pos":33,"type":"cell"}
{"cell_type":"markdown","id":"52dd99","input":"###  *Self Assessment:  Minimize to Maximize*","metadata":{"code_folding":[],"hidden":true},"pos":23,"type":"cell"}
{"cell_type":"markdown","id":"5451f0","input":"Let's see what this looks like for the TSP.  We'll use the subtour reversal algorithm, described in the textbook, to generate moves.  Here's what the local search looks like for the TSP:\n\n```\n choose a random tour  \n while shorter tours have been found in last max_tries\n     propose new tour with one random segment reversed and compute new distance\n     if acceptable (it will always be a valid tour) \n         if new shortest tour \n             remember it \n         else\n             reject new tour\n endwhile \n ```","metadata":{"hidden":true},"pos":71,"type":"cell"}
{"cell_type":"markdown","id":"54ae90","input":"### *Self-Assessment:  How many searches?*","metadata":{"hidden":true},"pos":61,"type":"cell"}
{"cell_type":"markdown","id":"57cf33","input":"Local search algorithms for continuous variables are generally based on approximating the objective function near the current search point, then using that approximation to compute an improved search point.  For instance if we can calculate the gradient (calculus) or approximate it, then a move along the gradient direction will increase the value of the function.  \n\nWe'll primarily use the `scipy.optimize` function `minimize` for local search on continuous functions.  You can read more about it below.  ","pos":11,"type":"cell"}
{"cell_type":"markdown","id":"6053b1","input":"The Rastrigin function is a common test case for optimization algorithms because it has many local minima.  The definition of the function is \n$$f(\\mathbf{x})=10 n+\\sum_{i=1}^{n}\\left[x_{i}^{2}-A \\cos \\left(2 \\pi x_{i}\\right)\\right]$$\nWhere $n$ is the dimensionality of input vector $\\mathbf{x}$.  For instance if $n=2$ then $\\mathbf{x} = (x_1, x_2)$.  The domain is restricted so that each $x_i \\in [-5.12, 5.12].$ .   Here is a graph of the the Rastrigin function with dimension $n=1.$","pos":50,"type":"cell"}
{"cell_type":"markdown","id":"6178f6","input":"### An example","pos":35,"type":"cell"}
{"cell_type":"markdown","id":"62589f","input":"## Another local search algorithm for TSP","metadata":{"heading_collapsed":true},"pos":81,"type":"cell"}
{"cell_type":"markdown","id":"634678","input":"### Video Walkthrough of this example","pos":31,"type":"cell"}
{"cell_type":"markdown","id":"663c1f","input":"## Example:  The Rastrigin Function","pos":49,"type":"cell"}
{"cell_type":"markdown","id":"66776c","input":"If we are maximizing a function of one variable, $f(x)$, we might choose to use 10 starting points.  For a function of two variables, $g(x,y)$ to get the same search power we would choose 10 points in the $x$ direction and 10 points in the $y$ direction to make a grid of $10^2 = 100$ starting points in the $xy$-plane.  For three variables we need $10^3 = 1000$ points in $xyz$-space.  For a function of $n$ variables we would need $10^n$ starting points. ($n$ is the same as `dim` in the code above.)\n\n*The volume of the search space grows exponentially with the number of variables or dimensionality of the problem.*\n\nThis is called the curse of dimensionality.  For high dimensional functions like those that occur in training neural networks and other applications with many local minima it can be very difficult to find the global minima because the volume of the search space grows exponentially with the number of variables.\n\nFor the Rastrigin function to find the global minimum you need an initial starting point in the interval (-0.5,0.5) in each dimension.  The search interval is [-5.12,5.12] in each dimension.  Thus the probability that a single uniformly sampled point in [-5.12,5.12] is $\\frac{1}{10.24} \\approx 0.0977$ (the ratio of the lengths of the two intervals).  The probability of finding the global minimum using local search from a uniformly sampled point in $n$ dimensions is $$\\left( \\frac{1}{10.24} \\right)^n.$$  That means we'd have to, on average, start $10.24^n$ local searches from uniformly sampled points to find the global minimum once.","metadata":{"hidden":true},"pos":60,"type":"cell"}
{"cell_type":"markdown","id":"67be48","input":"Note:  the approach outlined here for logisitic regression is very similar to the actual algorithms used by most software for computing logistic regression models. Many machine learning predictive models are trained by optimization.  To verify our results we check our results against those from Sci-kit Learn.  By default sklearn uses an L2 regularization term to avoid overfitting (more about this in DS740).  The amount of regularization is proportional to $1/C$ so we just use a huge $C$ to mimic no regularization.","pos":47,"type":"cell"}
{"cell_type":"markdown","id":"6bedf9","input":"The `summarize_districts` function below isn't used directly in the initialization, but it helps us by printing out the number of voters (in thousands) assigned to each district and shows us which districts are won by republicans.","pos":89,"type":"cell"}
{"cell_type":"markdown","id":"6c0d95","input":"Now we need to create an object of the `LocalSearcher` class.  We'll do that in the cell below and then explain each part:","pos":102,"type":"cell"}
{"cell_type":"markdown","id":"73eb3a","input":"## Video for TSP Local Search Code","metadata":{"heading_collapsed":true},"pos":72,"type":"cell"}
{"cell_type":"markdown","id":"74635e","input":"## Wyndor Example","metadata":{"hidden":true},"pos":7,"type":"cell"}
{"cell_type":"markdown","id":"75dc54","input":"Here is pseudo-code for a simple local search.  Many variations are possible, but they often look like this:\n```\n set starting state \n while local_condition \n     select a move \n     if acceptable \n         do the move \n         if new optimum \n             remember it \n endwhile \n ```","pos":68,"type":"cell"}
{"cell_type":"markdown","id":"76e10c","input":"That sure seemed like a lot of work, but notice that all the messy bookkeeping details of the local search are inherited from the `LocalSearcher` class and we don't have to pay attention to the details.  Instead we can focus on just the essence of the problem - the objective function and a procedure for generating a local search step or move.  You can change default values of search and seetings variables too.  For example, suppose we wanted to stop the search after making no progress for 300 iterations and wanted to print output every 200 iterations:","pos":106,"type":"cell"}
{"cell_type":"markdown","id":"7fcb28","input":"## Local Search for TSP","metadata":{"heading_collapsed":true},"pos":70,"type":"cell"}
{"cell_type":"markdown","id":"80fbda","input":"Optimization with discrete variables tends to be more complicated than with continuous variables.  In the continuous case we can take advantage of calculus or numerical methods to compute gradient search directions that allow us to move to nearby points that are closer to optimal.  However with discrete random variables there is no generic way to compute better nearby points.  Often the best we can do is find nearby points, which is usually problem specific, and try them to see if they produce closer to optimal results.\n\nWe'll look carefully at the traveling salesman problem (TSP).  In addition to the information about the TSP in the textbook, there is copious information available on the internet.","pos":66,"type":"cell"}
{"cell_type":"markdown","id":"86e7ad","input":"Below is a graph of the data along with the graph of the fitted sigmoid function that models the probality of $y=1$ at each $x$.  Don't worry, we'll see where the fitted curve comes from in a bit.","pos":37,"type":"cell"}
{"cell_type":"markdown","id":"8772cf","input":"## The curse of dimensionality","metadata":{"heading_collapsed":true},"pos":59,"type":"cell"}
{"cell_type":"markdown","id":"896344","input":"The following function can be used to switch the assignment of a randomly selected city to a randomly selected district.  The while loop prevents the new assigned district from being the same as the old assigned district (requires num_districts $\\geq 2$)","pos":93,"type":"cell"}
{"cell_type":"markdown","id":"8a1ce4","input":"### A univariate function","metadata":{"hidden":true},"pos":15,"type":"cell"}
{"cell_type":"markdown","id":"8f85fb","input":"Take a minute to see how this function is structured and perhaps glance at the documentation again.  `coef` is a one-dimensional array with shape (n,) that contains all $n$ optimization variables.  In this case there are two which we assign to $b_0$ and $b_1$.  `*args` is a pointer to tuple `args` that contains any additional parameters that should be passed to the function.  In the case `minimize` will be passing the tuple $(x,y)$ that contains the training data.  We'll pass `args = (x_hours, y_passed)`.","pos":44,"type":"cell"}
{"cell_type":"markdown","id":"9167e7","input":"# Optimization Basics (video)","metadata":{"heading_collapsed":true},"pos":2,"type":"cell"}
{"cell_type":"markdown","id":"943903","input":"### *Self Assessment: Gerrymandering Local Search*","pos":95,"type":"cell"}
{"cell_type":"markdown","id":"98c44a","input":"Lets investigate the fourth degree polynomial $$p(x) = x^4 + 2 x^3 + 3 x^2 + 2 x + 1.$$  Let's graph it to get an idea of the behavior. ","metadata":{"hidden":true},"pos":16,"type":"cell"}
{"cell_type":"markdown","id":"9a81a6","input":"Notes:\n\n* Often the starting state is one selected at random.  State refers to the \"state\" or values of the variables.\n\n* The local condition is a stopping condition.  It could be something like stopping after a fixed number of iterations or stopping after making no or insignificant process for a while.\n\n* Selecting a move is where things get problem specific.  Often the move involves a random change to the variables.\n\n* If acceptable means that we are checking to see that the state is feasible, that is, does it satisfy the constraints?","pos":69,"type":"cell"}
{"cell_type":"markdown","id":"9dd365","input":"You should read about quadratic programming in the textbook.  In short, the constraints are the same as they are in linear programming and the objective function can have degree 2 and interaction terms.  In Pyomo it is only a matter of changing the solver to one capable of solving quadratic programs, `ipopt`, instead of `glpk`.  Other solvers like CPLEX, a commercial solver, could also be used.  You  may need to install `ipopt` using conda on your own machine.","metadata":{"hidden":true},"pos":6,"type":"cell"}
{"cell_type":"markdown","id":"9e84e8","input":"## Example: Simple Logistic Regression","metadata":{"code_folding":[]},"pos":30,"type":"cell"}
{"cell_type":"markdown","id":"ab6278","input":"An object of the `LocalSearcher` class already has a method for doing the local search:\n\n```\ndef localsearch(self):\n    \"\"\"Minimizes the objective function value by local search.\n\n    Parameters\n    state : an initial arrangement of the system\n\n    Returns\n    (state, objective): the best state and objective function value found.\n    \"\"\"\n    self.iterations = 0\n    num_moves_no_improve = 0\n\n    # set initial state and compute initial objective value\n    self.best_x = self.copy_state(self.state)\n    self.best_f = self.objective()\n    self.update() # output to screen\n\n    # main local search loop\n    while num_moves_no_improve < self.max_no_improve:\n        num_moves_no_improve += 1\n        self.iterations += 1\n        curr_state = self.copy_state(self.state)\n        self.move() # stores new state with move in self.state\n        new_f = self.objective()\n        if new_f < self.best_f:\n            num_moves_no_improve = 0\n            self.best_x = self.copy_state(self.state)\n            self.best_f = new_f\n        else: # if move not improvement reset state to curr_state\n            self.state = self.copy_state(curr_state)\n        if( self.iterations % self.update_iter == 0): # output every update_iter iterations\n            self.update() # print output\n\n    # output one last time for final iteration\n    self.update()\n\n    # Return best state and energy\n    return self.best_x, self.best_f\n```\n\nNotice that this method works on the object itself.  We don't pass in an initial state or other data.  Instead we'll have to make an object of the `LocalSearcher`\nclass and then set the initial state in that object as we'll see below.  We'll also have to define two methods in our object:  `objective()` and `move()`.  The first contains the objective function to be minimized and the second contains the details for creating a local change, or move, to the current state (values of the decision variables).  If our objective function requires more than just the decision variables we'll also have to add that to the object by modifying the `__init__` constructor.\n\nTo solve a TSP problem we'll use the `sub_tour_reversal` and `tour_distance()` functions from above to define our `move()` and `objective()` methods respectively:","pos":100,"type":"cell"}
{"cell_type":"markdown","id":"ad1aaf","input":"We'll be minimizing the total length of a tour that visits all 48 state capitals in the continental United States and ends back in the same city in which it begins.  The latitudes and longitudes of the cities were projected onto a rectangular coordinate system with $x$ and $y$ coordinates representing positions in meters which we convert to kilometers.  We have stored the $x$ and $y$ coordinates and a distance matrix with distances between all of the cities in the json file `Caps48.json`.  First we load the data and define a function visualize tours of the 48 capitals.  We plot the best possible tour just to show how the plotting routine works.  The coordinates in the json file are in meters.\n\n**Here is the optimal tour.**","pos":75,"type":"cell"}
{"cell_type":"markdown","id":"c0861b","input":"Here is all the code in one cell for convenience:","pos":108,"type":"cell"}
{"cell_type":"markdown","id":"c69af5","input":"There appears to be only one minimum somewhere around $x=0$ or $x=-1$.  Since the function appears to be convex, the starting point doesn't matter.  Let's search for the minimum beginning at $x_0 = -2$:","metadata":{"hidden":true},"pos":20,"type":"cell"}
{"cell_type":"markdown","id":"c8d194","input":"An apartment complex has 250 apartments to rent and that their profit in thousands of dollars is given by the function \n$$P(x) = -0.008 x^2 + 3.1 x - 80.$$\nFind the maximum profit and how many apartments to rent to achieve the maximum profit.  Use minimize from scipy.optimize to find the maximum.  Review the video above to see how to \"flip\" the problem to find a maximum.","metadata":{"hidden":true},"pos":24,"type":"cell"}
{"cell_type":"markdown","id":"c9cfad","input":"## TSP Local Search Code","pos":74,"type":"cell"}
{"cell_type":"markdown","id":"d1b3b8","input":"The Rastrigin function isn't important as a real-life example, but it does serve as a good test problem with oodles of local minima and we know that global minimum occurs at the origin.  This is similar to what can happen in training in neural networks and other complex models except that we don't know where the global optimum is.\n\nA simple approach for trying to find the global minimum of a multi-modal function is called a **restart** or **multistart strategy** in which local searches are started at randomly generated initial points and the most optimal result of all the local searches is recorded.\n\nHere is pseudo-code for a multistart code:\n```\nfor num_searches:\n choose random initial state\n do local search\n if new optimum\n     remember it\nendfor\n```\n","pos":53,"type":"cell"}
{"cell_type":"markdown","id":"d1e507","input":"Here we define both the local \"move\" function which reverses a randomly selected tour segment to generate a new tour and the objective function which computes the length of the tour in kilometers.  The local search continues until `max_no_improve` iterations have occured in which no shorter tour was found.","pos":77,"type":"cell"}
{"cell_type":"markdown","id":"de0d15","input":"### *Self-Assessment:  Rastrigin with dim = 10*","pos":57,"type":"cell"}
{"cell_type":"markdown","id":"e00632","input":"# Local Search - Continuous Variables","pos":10,"type":"cell"}
{"cell_type":"markdown","id":"e8a488","input":"### *Self Assessment: How many searches when dim = 10?*","metadata":{"hidden":true},"pos":63,"type":"cell"}
{"cell_type":"markdown","id":"e8e8ac","input":"Approximately now many local searches are required to find the global minimum one time when dim = 10?  Is it surprising that you (very likely) didn't find it with 1000 local searches?  Explain","metadata":{"hidden":true},"pos":64,"type":"cell"}
{"cell_type":"markdown","id":"e9345a","input":"### *Self Assessment:  Finding Multiple Extrema*","metadata":{"hidden":true},"pos":28,"type":"cell"}
{"cell_type":"markdown","id":"ec1bb0","input":"How many iterations does it take to reliably find the global minimum with dim = 3?  With dim = 4?  Use the multi-start strategy.  There is not an exact answer to this question, just experiment with `num_local_searches` ... what is the smallest number of searches so that you find the global minimum value of 0 almost every time?","pos":56,"type":"cell"}
{"cell_type":"markdown","id":"fa0232","input":"In the next lesson we're going to use a Python package called `simanneal` that uses an object-oriented programming approach to optimizing a function with a simulated annealing algorithm.  We'll introduce an object oriented approach to local search in this lesson to help you understand how it works.  \nWe'll solve the Traveling Salesman Problem (TSP) from above using this approach.  To begin with we import the `LocalSearcher` class from the `localsearch` package contained in the same directory as this presentation.\n\n```\nfrom locsearch import LocalSearcher\n```","pos":99,"type":"cell"}
{"cell_type":"markdown","id":"fb1549","input":"Do 1000 local search with Rastrigin with dim = 10.  What is the smallest value you find?  How long do you think it would take to find the minimum from randomly chosen initial points like this?  Again, there is no right answer, just experiment to get an idea how increasing the number of variables can make it **much** more difficult to find the global minimum.","pos":58,"type":"cell"}
{"cell_type":"markdown","id":"fee847","input":"We can use the model to make predictions:","pos":39,"type":"cell"}
{"cell_type":"markdown","id":"ff7e87","input":"In the cell below we load the data and create an assignment of the 18 cities to the 10 districts.","pos":87,"type":"cell"}
{"id":0,"time":1609977673289,"type":"user"}
{"last_load":1609954620759,"type":"file"}