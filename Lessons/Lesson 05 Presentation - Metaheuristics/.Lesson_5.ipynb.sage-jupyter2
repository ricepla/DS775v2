{"backend_state":"ready","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":82309120},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"250.696px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"trust":true,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"8dc2b3","input":"","pos":26,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":1,"id":"8704b5","input":"# relies on data loaded in previous section\n\n# import numpy as np\n# from simanneal import Annealer\n\ndef tour_distance(tour, dist_mat):\n    distance = dist_mat[tour[-1]][tour[0]]\n    for gene1, gene2 in zip(tour[0:-1], tour[1:]):\n        distance += dist_mat[gene1][gene2]\n    return distance\n\ndef sub_tour_reversal(tour):\n    # reverse a random tour segment\n    num_cities = len(tour)\n    i, j = np.sort(np.random.choice(num_cities, 2, replace=False))\n    return np.concatenate((tour[0:i], tour[j:-num_cities + i - 1:-1],\n                              tour[j + 1:num_cities]))\nclass TravellingSalesmanProblem(Annealer):\n\n    # pass extra data (the distance matrix) into the constructor\n    def __init__(self, state, distance_matrix):\n        self.distance_matrix = distance_matrix\n        super(TravellingSalesmanProblem, self).__init__(state)  # important!\n\n    def move(self):\n        self.state = sub_tour_reversal(self.state)\n\n    def energy(self):\n        return tour_distance(self.state, self.distance_matrix)\n\n# load data (this may have to be adapted for different problems)\nwith open(\"data/HillierTSP.json\", \"r\") as tsp_data:\n    tsp = json.load(tsp_data)\ndistance_matrix = tsp[\"DistanceMatrix\"]\ninit_tour = np.random.permutation(np.arange(len(distance_matrix))).astype(int).tolist()\n\ntsp = TravellingSalesmanProblem(init_tour, distance_matrix)\ntsp.set_schedule(tsp.auto(minutes=.2)) #set approximate time to find results\n\nbest_tour, best_dist = tsp.anneal()\n\nbest_dist","output":{"0":{"ename":"NameError","evalue":"name 'Annealer' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-ebde8c296d6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     return np.concatenate((tour[0:i], tour[j:-num_cities + i - 1:-1],\n\u001b[1;32m     17\u001b[0m                               tour[j + 1:num_cities]))\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTravellingSalesmanProblem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAnnealer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# pass extra data (the distance matrix) into the constructor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Annealer' is not defined"]}},"pos":14,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":10,"id":"50c180","input":"pop_size = 50 # should be even due to the way we'll implement crossover\nind_size = 10\nlower = -5.12\nupper = 5.12\npop = np.random.uniform(low=lower, high=upper, size = (ind_size,pop_size))","pos":32,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":11,"id":"280277","input":"pop[:,0:5]","output":{"0":{"data":{"text/plain":"array([[-2.46967485, -1.73344591,  0.23386379, -0.79164187,  4.9866534 ],\n       [ 0.38866417,  0.1424723 , -1.09023296,  2.20400795,  2.5293183 ],\n       [-2.46203687,  3.03399292,  2.01473654,  3.31800661, -2.0275582 ],\n       [ 3.43003613, -0.13309903,  3.15668006, -2.26148204,  2.95972422],\n       [-4.82015204,  3.99811795, -2.46254942,  3.26575767, -1.67798834],\n       [-3.16536016,  3.20642583,  3.99713426,  3.7706293 , -3.17535383],\n       [-2.0859064 ,  4.30833516,  4.77397268,  2.16054709, -2.92647709],\n       [ 2.66090189,  4.52051064,  2.56350085,  0.16323386, -5.06776778],\n       [ 1.34613112,  1.10693989,  4.75955095,  2.76492882, -2.91977531],\n       [ 0.79473238,  1.00719259, -1.47304314, -1.71041591,  2.45285004]])"},"exec_count":11,"output_type":"execute_result"}},"pos":34,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":12,"id":"51366a","input":"def rastrigin(x):\n    x = np.array(x) # force a numpy arrray here so that the math below works\n    return np.sum(x**2 + 10 - 10 * np.cos(2 * np.pi * x) )\n\nfitness = np.zeros(pop_size) # initialize fitness array\nfor j in range(pop_size):\n    fitness[j] = rastrigin(pop[:,j])","pos":36,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":13,"id":"18c0ea","input":"fitness[0:5]","output":{"0":{"data":{"text/plain":"array([197.74245751, 141.04178712, 183.25311336, 151.8901815 ,\n       168.75665522])"},"exec_count":13,"output_type":"execute_result"}},"pos":38,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":14,"id":"6d5691","input":"# note that the smallest element is in position 3, the second smallest in position 1, the third smallest in postion 0, and the last smallest in position 2\narray = np.array([4,2,7,1])\nsorted_pos = array.argsort()\nsorted_pos","output":{"0":{"data":{"text/plain":"array([3, 1, 0, 2])"},"exec_count":14,"output_type":"execute_result"}},"pos":40,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":15,"id":"800e17","input":"array[sorted_pos]","output":{"0":{"data":{"text/plain":"array([1, 2, 4, 7])"},"exec_count":15,"output_type":"execute_result"}},"pos":42,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":16,"id":"8b3e0c","input":"sorted_pos = fitness.argsort()\nfitness = fitness[sorted_pos]\npop = pop[:,sorted_pos]\nfitness[0:10]","output":{"0":{"data":{"text/plain":"array([118.774547  , 119.79500968, 131.50145607, 141.04178712,\n       145.72944545, 148.79557909, 150.81377691, 151.3170401 ,\n       151.8901815 , 153.92298655])"},"exec_count":16,"output_type":"execute_result"}},"pos":44,"scrolled":true,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":17,"id":"2cc7a0","input":"tourn_size = 3\nselect_pop = np.zeros((ind_size,pop_size)) # initialize selected population\nsel_fitness = np.zeros(pop_size)\nfor j in range(pop_size):\n    subset_pos = np.random.choice(pop_size,tourn_size,replace=False) # select without replacement\n    smallest_pos = np.min(subset_pos) # choose index corresponding to lowest fitness\n    select_pop[:,j] = pop[:,smallest_pos]\n    sel_fitness[j] = fitness[smallest_pos]","pos":46,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":18,"id":"ff3409","input":"fitness","output":{"0":{"data":{"text/plain":"array([118.774547  , 119.79500968, 131.50145607, 141.04178712,\n       145.72944545, 148.79557909, 150.81377691, 151.3170401 ,\n       151.8901815 , 153.92298655, 155.46212845, 159.70530328,\n       159.94589787, 167.05174522, 168.75665522, 171.45722862,\n       171.81152829, 172.34936622, 176.64025969, 180.73552402,\n       183.25311336, 184.17233867, 184.22814298, 185.39846233,\n       186.04304522, 187.11351075, 187.49485975, 188.04234914,\n       188.39172768, 189.81699164, 191.04949815, 191.59389279,\n       193.2966523 , 193.54650768, 195.53645425, 197.74245751,\n       199.16668671, 202.20775472, 203.49387671, 204.18154832,\n       210.34653944, 215.29776058, 217.6491994 , 217.66855729,\n       221.52994653, 224.40396788, 233.96185396, 236.06537268,\n       243.96424369, 247.29926037])"},"exec_count":18,"output_type":"execute_result"}},"pos":48,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":19,"id":"f34c06","input":"sel_fitness","output":{"0":{"data":{"text/plain":"array([171.45722862, 185.39846233, 150.81377691, 171.45722862,\n       159.70530328, 148.79557909, 141.04178712, 145.72944545,\n       150.81377691, 215.29776058, 180.73552402, 151.3170401 ,\n       153.92298655, 159.70530328, 189.81699164, 186.04304522,\n       159.94589787, 153.92298655, 202.20775472, 150.81377691,\n       191.59389279, 118.774547  , 171.45722862, 172.34936622,\n       171.81152829, 118.774547  , 118.774547  , 180.73552402,\n       148.79557909, 119.79500968, 141.04178712, 119.79500968,\n       193.2966523 , 159.94589787, 151.3170401 , 197.74245751,\n       151.3170401 , 153.92298655, 184.22814298, 145.72944545,\n       151.8901815 , 183.25311336, 151.3170401 , 153.92298655,\n       197.74245751, 159.94589787, 119.79500968, 141.04178712,\n       153.92298655, 186.04304522])"},"exec_count":19,"output_type":"execute_result"}},"pos":49,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":2,"id":"b8e958","input":"# EXECUTE FIRST\n\n# computational imports\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.optimize import minimize\nimport json\nfrom simanneal import Annealer\n# plotting imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n# for reading files from urls\nimport urllib.request\n# display importt\nfrom IPython.display import display, IFrame\nfrom IPython.core.display import HTML\n\n# for playing videos, customize height and width if desired\ndef play_video(vid_name, w = 640, h = 360):\n    vid_path = \"https://media.uwex.edu/content/ds/ds775_r19/\"\n    return IFrame( vid_path + vid_name + \"/index.html\", width = w, height = h )\n\n# import notebook styling for tables and width etc.\nresponse = urllib.request.urlopen('https://raw.githubusercontent.com/DataScienceUWL/DS775v2/master/ds755.css')\nHTML(response.read().decode(\"utf-8\"));\n\n# for this notebook we get rid of a bunch of warnings that don't hurt anything\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"code_folding":[0]},"pos":0,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":2,"id":"bdc93a","input":"# execute this cell for video\nplay_video(\"ds775_lesson5_simulated-anneal-tsp\")","metadata":{"code_folding":[],"hidden":true},"output":{"0":{"data":{"text/html":"\n        <iframe\n            width=\"640\"\n            height=\"360\"\n            src=\"https://media.uwex.edu/content/ds/ds775_r19/ds775_lesson5_simulated-anneal-tsp/index.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ","text/plain":"<IPython.lib.display.IFrame at 0x7f4016f7e910>"},"exec_count":2,"output_type":"execute_result"}},"pos":6,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":20,"id":"2c53aa","input":"parent1 = np.arange(10) + 10 # use sequences to make it easy to see crossover\nparent2 = parent1 + 10\n\nchild1, child2 = parent1.copy(), parent2.copy()\ncx_point = 3\nchild1[0:cx_point], child2[0:cx_point] = parent2[0:cx_point], parent1[0:cx_point]\n\nprint('Parents')\nprint(parent1)\nprint(parent2)\nprint('\\nChildren')\nprint(child1)\nprint(child2)","output":{"0":{"name":"stdout","output_type":"stream","text":"Parents\n[10 11 12 13 14 15 16 17 18 19]\n[20 21 22 23 24 25 26 27 28 29]\n\nChildren\n[20 21 22 13 14 15 16 17 18 19]\n[10 11 12 23 24 25 26 27 28 29]\n"}},"pos":52,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":21,"id":"e18c66","input":"cx_prob = .8 # prob. that a pair produces offspring\ncx_pop = np.zeros((ind_size,pop_size)) # initialize crossover population\nfor j in range(int(pop_size/2)):  # pop_size must be even\n    parent1, parent2 = select_pop[:,2*j], select_pop[:,2*j+1]\n    child1, child2 = parent1.copy(), parent2.copy()\n    if np.random.uniform() < cx_prob: # crossover occurs\n        cx_point = np.random.randint(1,ind_size) # crossover point between 0 and ind_size-2\n        child1[0:cx_point], child2[0:cx_point] = parent2[0:cx_point], parent1[0:cx_point]\n    cx_pop[:,2*j] = child1\n    cx_pop[:,2*j+1] = child2","pos":54,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":22,"id":"f958ed","input":"print('Columns are first 6 parents')\npd.DataFrame(select_pop[:,0:6])","output":{"0":{"name":"stdout","output_type":"stream","text":"Columns are first 6 parents\n"},"1":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.259452</td>\n      <td>3.996043</td>\n      <td>-3.189071</td>\n      <td>1.259452</td>\n      <td>-1.080551</td>\n      <td>4.378548</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.793561</td>\n      <td>-5.075288</td>\n      <td>-0.625561</td>\n      <td>2.793561</td>\n      <td>-1.326925</td>\n      <td>-1.041320</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.789222</td>\n      <td>-1.565322</td>\n      <td>-0.498572</td>\n      <td>-0.789222</td>\n      <td>3.582920</td>\n      <td>-0.917647</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.761729</td>\n      <td>1.385284</td>\n      <td>-2.855964</td>\n      <td>-0.761729</td>\n      <td>-4.059507</td>\n      <td>1.176314</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.160462</td>\n      <td>-3.619587</td>\n      <td>-0.625243</td>\n      <td>-1.160462</td>\n      <td>-2.543212</td>\n      <td>-0.730030</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-4.288384</td>\n      <td>2.953856</td>\n      <td>-3.017128</td>\n      <td>-4.288384</td>\n      <td>-1.130372</td>\n      <td>3.356663</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-2.152799</td>\n      <td>2.454535</td>\n      <td>1.484926</td>\n      <td>-2.152799</td>\n      <td>2.759201</td>\n      <td>0.552228</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2.484776</td>\n      <td>-0.171563</td>\n      <td>0.133820</td>\n      <td>2.484776</td>\n      <td>0.728589</td>\n      <td>-0.429646</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-4.747290</td>\n      <td>-4.960455</td>\n      <td>3.196249</td>\n      <td>-4.747290</td>\n      <td>-0.408034</td>\n      <td>-0.097254</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3.265305</td>\n      <td>1.882791</td>\n      <td>-1.314815</td>\n      <td>3.265305</td>\n      <td>3.152594</td>\n      <td>4.158117</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"          0         1         2         3         4         5\n0  1.259452  3.996043 -3.189071  1.259452 -1.080551  4.378548\n1  2.793561 -5.075288 -0.625561  2.793561 -1.326925 -1.041320\n2 -0.789222 -1.565322 -0.498572 -0.789222  3.582920 -0.917647\n3 -0.761729  1.385284 -2.855964 -0.761729 -4.059507  1.176314\n4 -1.160462 -3.619587 -0.625243 -1.160462 -2.543212 -0.730030\n5 -4.288384  2.953856 -3.017128 -4.288384 -1.130372  3.356663\n6 -2.152799  2.454535  1.484926 -2.152799  2.759201  0.552228\n7  2.484776 -0.171563  0.133820  2.484776  0.728589 -0.429646\n8 -4.747290 -4.960455  3.196249 -4.747290 -0.408034 -0.097254\n9  3.265305  1.882791 -1.314815  3.265305  3.152594  4.158117"},"exec_count":22,"output_type":"execute_result"}},"pos":56,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":23,"id":"97329f","input":"pd.DataFrame(cx_pop[:,0:6])","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.259452</td>\n      <td>3.996043</td>\n      <td>1.259452</td>\n      <td>-3.189071</td>\n      <td>4.378548</td>\n      <td>-1.080551</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.793561</td>\n      <td>-5.075288</td>\n      <td>2.793561</td>\n      <td>-0.625561</td>\n      <td>-1.041320</td>\n      <td>-1.326925</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.789222</td>\n      <td>-1.565322</td>\n      <td>-0.789222</td>\n      <td>-0.498572</td>\n      <td>3.582920</td>\n      <td>-0.917647</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.761729</td>\n      <td>1.385284</td>\n      <td>-0.761729</td>\n      <td>-2.855964</td>\n      <td>-4.059507</td>\n      <td>1.176314</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.160462</td>\n      <td>-3.619587</td>\n      <td>-1.160462</td>\n      <td>-0.625243</td>\n      <td>-2.543212</td>\n      <td>-0.730030</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-4.288384</td>\n      <td>2.953856</td>\n      <td>-4.288384</td>\n      <td>-3.017128</td>\n      <td>-1.130372</td>\n      <td>3.356663</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-2.152799</td>\n      <td>2.454535</td>\n      <td>-2.152799</td>\n      <td>1.484926</td>\n      <td>2.759201</td>\n      <td>0.552228</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2.484776</td>\n      <td>-0.171563</td>\n      <td>2.484776</td>\n      <td>0.133820</td>\n      <td>0.728589</td>\n      <td>-0.429646</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-4.747290</td>\n      <td>-4.960455</td>\n      <td>-4.747290</td>\n      <td>3.196249</td>\n      <td>-0.408034</td>\n      <td>-0.097254</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3.265305</td>\n      <td>1.882791</td>\n      <td>-1.314815</td>\n      <td>3.265305</td>\n      <td>3.152594</td>\n      <td>4.158117</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"          0         1         2         3         4         5\n0  1.259452  3.996043  1.259452 -3.189071  4.378548 -1.080551\n1  2.793561 -5.075288  2.793561 -0.625561 -1.041320 -1.326925\n2 -0.789222 -1.565322 -0.789222 -0.498572  3.582920 -0.917647\n3 -0.761729  1.385284 -0.761729 -2.855964 -4.059507  1.176314\n4 -1.160462 -3.619587 -1.160462 -0.625243 -2.543212 -0.730030\n5 -4.288384  2.953856 -4.288384 -3.017128 -1.130372  3.356663\n6 -2.152799  2.454535 -2.152799  1.484926  2.759201  0.552228\n7  2.484776 -0.171563  2.484776  0.133820  0.728589 -0.429646\n8 -4.747290 -4.960455 -4.747290  3.196249 -0.408034 -0.097254\n9  3.265305  1.882791 -1.314815  3.265305  3.152594  4.158117"},"exec_count":23,"output_type":"execute_result"}},"pos":57,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":24,"id":"e2e6f2","input":"mut_prob = 1.0 # all individuals can mutate, usually around 0.1 to 0.3\nind_prob = 0.1\nsigma = (upper-lower)/6\nmut_pop = np.zeros((ind_size,pop_size)) # initialize mutation population\nfor j in range(pop_size):\n    individual = cx_pop[:,j].copy() # copy is necessary to avoid conflicts in memory\n    if np.random.uniform()<mut_prob:\n        for i in range(ind_size):\n            if np.random.uniform()<ind_prob:\n                individual[i] += np.random.normal(0,sigma)\n                if individual[i] < lower: # clipping to bounds\n                    individual[i] = lower\n                if individual[i] > upper:\n                    individual[i] = upper\n    mut_pop[:,j] = individual.copy() # copy is necessary to avoid conflicts in memory","pos":60,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":25,"id":"736896","input":"pd.DataFrame(cx_pop[:,0:10]-mut_pop[:,0:10])","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.541928</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.325189</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.864083</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>1.63687</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.192619</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>-0.89755</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.621266</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-2.256906</td>\n      <td>-2.201217</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.969339</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-0.048660</td>\n      <td>0.159545</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"          0         1    2         3         4    5        6        7    8  \\\n0  2.541928  0.000000  0.0  0.000000  0.325189  0.0  0.00000  0.00000  0.0   \n1 -0.864083  0.000000  0.0  0.000000  0.000000  0.0  0.00000  1.63687  0.0   \n2  1.192619  0.000000  0.0  0.000000  0.000000  0.0 -0.89755  0.00000  0.0   \n3  0.000000  0.000000  0.0  0.000000  0.000000  0.0  0.00000  0.00000  0.0   \n4  0.000000  0.000000  0.0  0.000000  0.000000  0.0  0.00000  0.00000  0.0   \n5  0.000000  0.000000  0.0  0.000000  0.000000  0.0  0.00000  0.00000  0.0   \n6 -2.256906 -2.201217  0.0  0.000000  0.000000  0.0  0.00000  0.00000  0.0   \n7  0.000000  0.000000  0.0  1.969339  0.000000  0.0  0.00000  0.00000  0.0   \n8 -0.048660  0.159545  0.0  0.000000  0.000000  0.0  0.00000  0.00000  0.0   \n9  0.000000  0.000000  0.0  0.000000  0.000000  0.0  0.00000  0.00000  0.0   \n\n          9  \n0  0.000000  \n1  0.000000  \n2  0.000000  \n3  0.000000  \n4  0.621266  \n5  0.000000  \n6  0.000000  \n7  0.000000  \n8  0.000000  \n9  0.000000  "},"exec_count":25,"output_type":"execute_result"}},"pos":62,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":26,"id":"6993b0","input":"pop = mut_pop.copy()\nfor j in range(pop_size):\n    fitness[j] = rastrigin(pop[:,j])\nfitness[0:10]","output":{"0":{"data":{"text/plain":"array([178.23518768, 201.04815493, 165.52443075, 161.64791028,\n       159.28192524, 129.80684076, 139.94895584, 161.21437307,\n       150.81377691, 215.47687058])"},"exec_count":26,"output_type":"execute_result"}},"pos":65,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":27,"id":"91c207","input":"play_video(\"ds775_lesson5_genetic-alg-assembled\")","output":{"0":{"data":{"text/html":"\n        <iframe\n            width=\"640\"\n            height=\"360\"\n            src=\"https://media.uwex.edu/content/ds/ds775_r19/ds775_lesson5_genetic-alg-assembled/index.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ","text/plain":"<IPython.lib.display.IFrame at 0x7f3ff3a77e20>"},"exec_count":27,"output_type":"execute_result"}},"pos":67,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":28,"id":"f2606a","input":"pop_size = 100 # should be even due to the way we'll implement crossover\nind_size = 10 # determines number of input variables for Rastrigin and each individual\nlower = -5.12 # lower and upper bounds on the real variables\nupper = 5.12\ntourn_size = 3 # tournament size for selection\ncx_prob = 0.8 # probability a pair of parents crossover to produce two children\nmut_prob = 0.2 # probability an individual mutates\nind_prob = 0.1 # probability each variable in an individual mutates\nsigma = (upper-lower)/6 # standard deviation (scale) for gaussian mutations\nnum_iter = 2000 # number of genetic algorithm mutations\nupdate_iter = 100 # how often to display output\n\nstats = np.zeros((num_iter+1,3)) # for collecting statistics\n\n# objective or fitness function\ndef rastrigin(x):\n    x = np.array(x) # force a numpy arrray here so that the math below works\n    return np.sum(x**2 + 10 - 10 * np.cos(2 * np.pi * x) )\n\n#initialize population and fitness\npop = np.random.uniform(low=lower, high=upper, size = (ind_size,pop_size))\nfitness = np.zeros(pop_size)\nfor j in range(pop_size):\n    fitness[j] = rastrigin(pop[:,j])\n\n# initialize stats and output\nbest_fitness = min(fitness)\nstats[0,:] = np.array([0,best_fitness, best_fitness])\nprint('Iteration | Best this iter |    Best ever')\n\nfor iter in range(num_iter):\n    # tournament selection\n    sorted_pos = fitness.argsort() # sort pop by increasing fitness\n    fitness = fitness[sorted_pos]\n    pop = pop[:,sorted_pos]\n    select_pop = np.zeros((ind_size,pop_size)) # initialize selected population\n    for j in range(pop_size):\n        subset_pos = np.random.choice(pop_size,tourn_size,replace=False) # select without replacement\n        smallest_pos = np.min(subset_pos) # choose index corresponding to lowest fitness\n        select_pop[:,j] = pop[:,smallest_pos]\n\n    # one-point crossover (mating)\n    cx_pop = np.zeros((ind_size,pop_size)) # initialize crossover population\n    for j in range(int(pop_size/2)):  # pop_size must be even\n        parent1, parent2 = select_pop[:,2*j], select_pop[:,2*j+1]\n        child1, child2 = parent1.copy(), parent2.copy()\n        if np.random.uniform() < cx_prob: # crossover occurs\n            cx_point = np.random.randint(1,ind_size) # crossover point between 0 and ind_size-2\n            child1[0:cx_point], child2[0:cx_point] = parent2[0:cx_point], parent1[0:cx_point]\n        cx_pop[:,2*j] = child1\n        cx_pop[:,2*j+1] = child2\n\n    # gaussian mutation (rewritten to remove nested loop for speed)\n    mut_pop = np.zeros((ind_size,pop_size)) # initialize mutation population\n    for j in range(pop_size):\n        individual = cx_pop[:,j].copy() # copy is necessary to avoid conflicts in memory\n        if np.random.uniform()<mut_prob:\n            individual = individual + np.random.normal(0,sigma,ind_size)*(np.random.uniform(size=ind_size)<ind_prob)\n            individual = np.maximum(individual,lower) # clip to lower bound\n            individual = np.minimum(individual,upper) # clip to upper bound\n        mut_pop[:,j] = individual.copy() # copy is necessary to avoid conflicts in memory\n\n    # fitness evaluation with local search\n    pop = mut_pop.copy()\n    for j in range(pop_size):\n        fitness[j] = rastrigin(pop[:,j])\n\n    # collect stats and output to screen\n    min_fitness = min(fitness) # best for this iteration\n    if min_fitness < best_fitness: # best for all iterations\n        best_fitness = min_fitness\n        index = np.argmin(fitness)\n        best_x = pop[:,index]\n\n    stats[iter+1,:] = np.array([iter+1,min_fitness, best_fitness])\n    if (iter+1) % update_iter == 0:\n        print(f\"{stats[iter+1,0]:9.0f} | {stats[iter+1,1]:14.3e} | {stats[iter+1,2]:12.3e}\")\n        \nprint(f\"The minimum value found of the Rastrigin function is {best_fitness:.4f}\")\nprint(\"The location of that minimum is:\")\nprint('(',', '.join(f\"{x:.4f}\" for x in best_x),')')","output":{"0":{"name":"stdout","output_type":"stream","text":"Iteration | Best this iter |    Best ever\n"},"1":{"name":"stdout","output_type":"stream","text":"      100 |      5.415e+00 |    5.415e+00\n"},"10":{"name":"stdout","output_type":"stream","text":"     1000 |      1.388e-02 |    1.388e-02\n"},"11":{"name":"stdout","output_type":"stream","text":"     1100 |      1.388e-02 |    1.388e-02\n"},"12":{"name":"stdout","output_type":"stream","text":"     1200 |      1.075e-02 |    1.075e-02\n"},"13":{"name":"stdout","output_type":"stream","text":"     1300 |      1.075e-02 |    1.075e-02\n"},"14":{"name":"stdout","output_type":"stream","text":"     1400 |      8.559e-03 |    8.559e-03\n"},"15":{"name":"stdout","output_type":"stream","text":"     1500 |      8.010e-03 |    8.010e-03\n"},"16":{"name":"stdout","output_type":"stream","text":"     1600 |      8.010e-03 |    8.010e-03\n"},"17":{"name":"stdout","output_type":"stream","text":"     1700 |      7.942e-03 |    7.942e-03\n"},"18":{"name":"stdout","output_type":"stream","text":"     1800 |      7.942e-03 |    7.942e-03\n"},"19":{"name":"stdout","output_type":"stream","text":"     1900 |      7.942e-03 |    7.942e-03\n"},"2":{"name":"stdout","output_type":"stream","text":"      200 |      1.281e+00 |    1.281e+00\n"},"20":{"name":"stdout","output_type":"stream","text":"     2000 |      7.942e-03 |    7.942e-03\nThe minimum value found of the Rastrigin function is 0.0079\nThe location of that minimum is:\n( 0.0024, -0.0013, 0.0002, -0.0024, -0.0031, 0.0000, -0.0006, -0.0000, 0.0037, -0.0017 )\n"},"3":{"name":"stdout","output_type":"stream","text":"      300 |      2.654e-02 |    2.654e-02\n"},"4":{"name":"stdout","output_type":"stream","text":"      400 |      1.883e-02 |    1.883e-02\n"},"5":{"name":"stdout","output_type":"stream","text":"      500 |      1.883e-02 |    1.883e-02\n"},"6":{"name":"stdout","output_type":"stream","text":"      600 |      1.883e-02 |    1.883e-02\n"},"7":{"name":"stdout","output_type":"stream","text":"      700 |      1.883e-02 |    1.883e-02\n"},"8":{"name":"stdout","output_type":"stream","text":"      800 |      1.883e-02 |    1.883e-02\n"},"9":{"name":"stdout","output_type":"stream","text":"      900 |      1.870e-02 |    1.870e-02\n"}},"pos":68,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":29,"id":"913a05","input":"play_video(\"ds775_lesson5_ordered-crossover\")","output":{"0":{"data":{"text/html":"\n        <iframe\n            width=\"640\"\n            height=\"360\"\n            src=\"https://media.uwex.edu/content/ds/ds775_r19/ds775_lesson5_ordered-crossover/index.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ","text/plain":"<IPython.lib.display.IFrame at 0x7f3ff82ed1c0>"},"exec_count":29,"output_type":"execute_result"}},"pos":72,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":3,"id":"531b94","input":"# import numpy as np\n# import json\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# sns.set_style(\"darkgrid\")\n\n# load data (this may have to be adapted for different problems)\nwith open(\"data/HillierTSP.json\", \"r\") as tsp_data:\n    tsp = json.load(tsp_data)\ndistance_matrix = tsp[\"DistanceMatrix\"]\nindividual_size = tsp[\"TourSize\"]\n\n# define objective function\ndef tour_distance(individual, dist_mat):\n    distance = dist_mat[individual[-1]][individual[0]]\n    for gene1, gene2 in zip(individual[0:-1], individual[1:]):\n        distance += dist_mat[gene1][gene2]\n    return distance\n\ndef sub_tour_reversal(tour):\n    # reverse a random tour segment\n    num_cities = len(tour)\n    i, j = np.sort(np.random.choice(num_cities, 2, replace=False))\n    return np.concatenate((tour[0:i], tour[j:-num_cities + i - 1:-1],\n                              tour[j + 1:num_cities]))\n\n# Random Number Seed\n# if you want reproducible results, then uncomment the following line\n# and play with the seed value until you get a result you like. If you run \n# it again with the same value, then you'll get the same result.\n# np.random.seed(123)\n\ndef simanneal_tsp(init_state, dist_mat, max_no_improve, init_temp, alpha): ###\n    '''\n    We use state to refer to the values of the input variable(s) for the objective function.\n    For the TSP problem, the state is a tour of the cities.\n    We use obj to refer to the objective function value.\n    For the TSP problem, obj is the total distance of the tour.\n    \n    To adapt this for another minimization problem, \n    only the lines with tour_distance and sub_tour_reversal need to change \n    to give a different objective function and a different move function.\n    Additional arguments to the objective function should be passed into the search function\n    similar to how we passed in dist_mat abov\n    '''\n\n    curr_state = init_state\n    curr_obj = tour_distance(curr_state, dist_mat)\n    best_state = curr_state  ###\n    best_obj = curr_obj  ###\n\n    # stop search if no better state is found within max_no_improve iterations\n    num_moves_no_improve = 0\n    iterations = 0\n    temp = init_temp\n\n    # save history for plotting after optimization\n    history = np.array([[iterations, curr_obj, best_obj]])  ###\n\n    while (num_moves_no_improve < max_no_improve):\n        num_moves_no_improve += 1\n        iterations += 1  # just for tracking\n        new_state = sub_tour_reversal(curr_state) # make a move\n        new_obj = tour_distance(new_state, dist_mat)\n        delta = curr_obj - new_obj ###\n        prob = np.exp(min(delta, 0) / temp) ### # compute prob accept uphill move\n\n        if new_obj < curr_obj or np.random.uniform() < prob : ### # accept if decrease or rand < prob\n            curr_state = new_state\n            curr_obj = new_obj\n            if curr_obj < best_obj: ### # keep track of best ever\n                best_state = curr_state ###\n                best_obj = curr_obj ###\n                num_moves_no_improve = 0 ###\n\n        temp *= alpha ###\n\n        history = np.vstack( (history, np.array([[iterations,curr_obj,best_obj]]) ) ) ###\n\n    return best_state, best_obj, iterations, history\n\n# apply the simanneal_tsp() function to our seven city problem\nnum_cities = len(distance_matrix)\ninit_tour = np.random.permutation(np.arange(num_cities))\n\nbest_tour, best_dist, iterations, history = simanneal_tsp(init_tour, distance_matrix, 200, 100, .995)\nbest_dist","metadata":{"hidden":true},"output":{"0":{"data":{"text/plain":"63"},"exec_count":3,"output_type":"execute_result"}},"pos":7,"scrolled":true,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":30,"id":"58f9bb","input":"# Ordered Crossover on Sequences in Numpy\nparent1 = np.array([0, 1, 2, 3, 4, 5, 6])\nparent2 = np.array([3, 5, 6, 2, 0, 4, 1])\n\nind_size = parent1.shape[0]\n\n# uncomment the line below to choose subsequence randomly in your code\n# swap_idx = np.sort(np.random.randint(0,ind_size,2))\n\n# delete this for your code, we want a fixed sequence for our example\nswap_idx = np.array([ 3, 5]) # subseq in positions 3 through 5 inclusive\n\nchild1,child2 = parent2.copy(), parent1.copy()\n\nhole = np.full( ind_size, False, dtype = bool)\nhole[swap_idx[0]:swap_idx[1]+1] = True\n\nchild1[~hole] = np.array([x for x in parent1 if x not in parent2[hole]])\nchild2[~hole] = np.array([x for x in parent2 if x not in parent1[hole]])\n\nprint(hole)\nprint(parent1[hole])\nprint(parent2[hole])\nprint(parent1,parent2)\nprint(child1,child2)","output":{"0":{"name":"stdout","output_type":"stream","text":"[False False False  True  True  True False]\n[3 4 5]\n[2 0 4]\n[0 1 2 3 4 5 6] [3 5 6 2 0 4 1]\n[1 3 5 2 0 4 6] [6 2 0 3 4 5 1]\n"}},"pos":74,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":30,"id":"d64e4d","input":"","metadata":{"code_folding":[]},"pos":80,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":31,"id":"d65f9e","input":"pop = np.empty((7,10),dtype=int) # create empty array for ind_size = 7 and pop_size = 10\nfor j in range(10):\n    pop[:,j] = np.random.permutation(7)\n\npd.DataFrame(pop)","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>6</td>\n      <td>5</td>\n      <td>0</td>\n      <td>6</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>3</td>\n      <td>6</td>\n      <td>5</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>4</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>5</td>\n      <td>2</td>\n      <td>3</td>\n      <td>6</td>\n      <td>4</td>\n      <td>0</td>\n      <td>4</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4</td>\n      <td>5</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>6</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5</td>\n      <td>6</td>\n      <td>3</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   0  1  2  3  4  5  6  7  8  9\n0  2  4  4  4  2  6  5  0  6  4\n1  3  3  6  5  0  2  1  3  1  6\n2  1  0  0  6  4  3  2  2  3  1\n3  4  5  2  3  6  4  0  4  5  2\n4  0  1  1  0  3  1  4  5  4  3\n5  6  2  5  1  1  0  3  6  0  5\n6  5  6  3  2  5  5  6  1  2  0"},"exec_count":31,"output_type":"execute_result"}},"pos":76,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":4,"id":"4575b3","input":"# plot the progress of the search for visualization\n# it isn't necessary to do this in the homework, but you're welcome to do so\n\nfig = plt.figure(figsize=(8, 6))\nline_min, = plt.plot(history[:,0], history[:,1], label='Curr. Dist.',color='red')\nline_curr, = plt.plot(history[:,0],history[:,2], label='Best. Dist.')\nplt.xlabel('Generation')\nplt.ylabel('Distance')\nplt.legend(handles=[line_curr, line_min])\nplt.title('Smallest Dist. Found: {:d}'.format(int(best_dist)));","metadata":{"hidden":true},"output":{"0":{"data":{"image/png":"652ee0590b64d0bb32083f0cd95374254711126b","text/plain":"<Figure size 576x432 with 1 Axes>"},"exec_count":4,"metadata":{"image/png":{"height":386,"width":500}},"output_type":"execute_result"}},"pos":8,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":5,"id":"5a180c","input":"# execute this cell for video\nplay_video(\"ds775_lesson5_simanneal-package-on-tsp\")","metadata":{"hidden":true},"output":{"0":{"data":{"text/html":"\n        <iframe\n            width=\"640\"\n            height=\"360\"\n            src=\"https://media.uwex.edu/content/ds/ds775_r19/ds775_lesson5_simanneal-package-on-tsp/index.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ","text/plain":"<IPython.lib.display.IFrame at 0x7f3ff9f1c070>"},"exec_count":5,"output_type":"execute_result"}},"pos":13,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":7,"id":"1c784d","input":"# define objective function and show a contour plot\n\ndef f(xy):\n    obj = 0.2 + sum(xy**2 - 0.1*np.cos(6*np.pi*xy))\n    return obj\n\n# we could have written the objective function like this for transparency:\n# if the argument is a list with [ numpy array of x's, numpy array of y's]\n# def f(xy):\n#     x = xy[0]\n#     y = xy[1]\n#     obj = 0.2 + x**2 + y**2 - 0.1*np.cos(6*np.pi*x) - 0.1*np.cos(6*np.pi*y)\n#     return obj\n\n# see script for details of plot\n%run scripts/bumpy_contours.py","metadata":{"code_folding":[],"hidden":true},"output":{"0":{"data":{"image/png":"44e21a10b473130d943bbdf38442b608b4a89f4c","text/plain":"<Figure size 576x576 with 1 Axes>"},"exec_count":7,"metadata":{"image/png":{"height":494,"width":523}},"output_type":"execute_result"}},"pos":21,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":8,"id":"a5cea3","input":"%run scripts/bumpy_2d.py","output":{"0":{"data":{"iframe":"b6097120804c793bb781f24bf80f0b7f5a2f65a6"},"exec_count":8,"output_type":"execute_result"}},"pos":23,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":9,"id":"e52309","input":"play_video(\"ds775_lesson5_genetic-alg-steps\")","output":{"0":{"data":{"text/html":"\n        <iframe\n            width=\"640\"\n            height=\"360\"\n            src=\"https://media.uwex.edu/content/ds/ds775_r19/ds775_lesson5_genetic-alg-steps/index.html\"\n            frameborder=\"0\"\n            allowfullscreen\n        ></iframe>\n        ","text/plain":"<IPython.lib.display.IFrame at 0x7f3ffa5ff0a0>"},"exec_count":9,"output_type":"execute_result"}},"pos":30,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"0ed82e","input":"If we now index the array using the sorted_pos as the index we'll get the elements of the array in increasing order:","pos":41,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"15da44","input":"## Genetic Algorithm Step by Step\n\nWe'll write a genetic algorithm to minimize a 10 dimensional (10 input variables) Rastrigin function.  The population will be stored in a numpy array with the individuals stored as columns so the array will have 10 rows (one for each input variable) and the number of columns will correspond to the population size.  The full algorithm is in one cell further below, but first we'll break down each step.\n\n**For more help go here:** A fantastic place to get more details about genetic algorithms and the various bits and pieces is this <a href=\"https://www.tutorialspoint.com/genetic_algorithms/index.htm\" target=\"_blank\">free online tutorial at tutorialspoint.com.</a>\n\nThe video in the next cell walks through the development of genetic algorithm code in this section:","pos":29,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"1e3060","input":"To visualize the mutations we'll print out the difference in the first 10 individuals between the crossover population and the new mutated population.  Most of the differences should be zero, but approximately 10% will differ by the random amount selected from the normal distribution:","pos":61,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"2bea14","input":"Let's print out the first 5 values of fitness corresponding to the first 5 individuals (columns) of the population","pos":37,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"2eddde","input":"## Mating, Mutation, and Initialization for Other Variable Types\n\nThe Rastrigin example above demonstrates One Point Crossover and Gaussian Mutation for problems with real variables, but other common scenarios include integer, binary, and permutation variables.  We can't even begin to cover all of the possible crossover and mutation operators (these are just what the algorithms are called in genetic algorithm world), but we'll mention a few that you'll explore in the homework.\n\n### Real Variables (Rastrigin)\n\nGaussian mutation is common, but One Point Crossover is not as common as Blended Crossover for real variable optimization.  In Blended Crossover, or BX$\\alpha$-crossover, each new variable in the resulting child is chosen from an interval that overlaps the two parents.  The following picture helps explain it:  \n\n<img src=\"images/blended_crossover.png\" width = 400>\n\nLet $x_i$ and $y_i$ be the variables from the two parents with $x_i < y_i$.  The idea is to sample uniformly from an interval that includes $x_i$ and $y_i$ but is expanded by, for example 20%, in each direction.  The exact amount of expansion is determined by the parameter $\\alpha$ which is usually between 0 and 1.  Values of $\\alpha$ are typically around 0.1 or 0.2.  \n\nFor each new variable, $z_i$ in the child here is the algorithm:\n1.  extract the corresponding variables $x_i$ and $y_i$ from the parents\n2.  find the min and max of $x_i$ and $y_i$ then range = $|x_i - y_i|$\n3.  the new variable $z_i$ is a random uniform number in the range [ min - $\\alpha$ * range, max + $\\alpha$ * range]\n\nSo if a pair of parents is randomly selected to mate, then form two children by looping (twice) over the parent variables and following the algorithm above for each pair.\n\nBlended Crossover seems to work better than One Point Crossover for problems with real variables.\n\n**Example initialization:**\n```\npop = np.random.uniform(3,5,size=(4,10))\n```\nCreates a $4 \\times 10$ array of random real numbers in the range [3,5].\n\n### Integer Variables (Gerrymandering Problem)\n\nThe individuals consist of integer values variables from a certain range.  One Point Crossover is suitable for mating  although other choices are possible.  A common mutation operator is to consider each integer $x_i$ in the individual and change it, with probability `ind_prob`, to a randomly sampled integer, $z_i$ from the suitable range.\n\n**Example initialization:**\n```\npop = np.random.randint(-5,23,size=(4,10))\n```\nCreates a $4 \\times 10$ array of random integers in the range [-5, 23].  This corresponds to `pop_size = 10` and `ind_size = 4.`\n\n\n### Binary Variables (Knapsack Problem)\n\nBinary variables are a special case of integer variables with only 0 and 1 allowed.  One Point Crossover is common here.  Mutations are commonly called \"flipping a bit\" because 0's are toggled to 1's and 1's to 0's.  In a bit flipping mutation each variable is randomly switched with probability `ind_prob`.\n\nIt is common to represent the binary variables as 0 and 1 or as False and True boolean variables.  Either one can be used in the homework.\n\n**Example initialization:**\n```\n# 0 and 1\npop = np.random.randint(0,2,size=(4,10))\n# False and True\npop = np.random.randint(0,2,size=(4,10)).astype(bool)\n```\nCreates binary populations.  Recall that when specifying a range of integers in Python most packages and data structures don't include the top number in the range.\n\n### Permutation Variables (TSP)\n\nThese can come from problems where we are looking for the best order for a process of some kind.  For instance in the Traveling Salesman Problem we are trying to find the order to visit cities 1 through 7 (and back to 1) that minimizes the total distance traveled.  The crossover and mutation operators we've discussed so far don't work in this situation.\n\nA commonly used form of crossover is called Ordered Crossover in which two subsequences are swapped between the parents and the remainder of the variables filled in by preserving the order of variables.  The video below gives an example of how this works.","pos":71,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"3be4bd","input":"Copy the gerrymandering code from Lesson 4 and adapt the simulated annealing code above to try to find a solution in which republicans win 9 of the 10 districts.  Beware that you're trying to maximize the fitness.  The simplest way to use a minimization algorithm to maximize is to negate the fitness value.  If you start with simanneal_tsp then you should need only minor changes.\n\nYou'll have to change the values of the initial temperature, max_no_improve, and alpha.  The positive initial temperature should be similar to the initial fitness values (in magnitude).  Increasing max_no_improve allows the search to explore for longer.  Increasing alpha means the temperature doesn't decrease as quickly so that more uphill moves are allowed and the algorithm can explore more of the search space.","metadata":{"hidden":true},"pos":10,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"413c82","input":"## Other Selection Operators\n\nOther kinds of selection are possible, but we've found tournament selection to work well in practice.  Choosing small tournament sizes (> 1) leads to a more diverse selection process while large tournament sizes tend to promote only the fittest members of the population.  We won't explore other selection operators in the homework.","pos":77,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"4360c3","input":"## Using the `simanneal` package (video)","metadata":{"heading_collapsed":true,"hidden":true},"pos":11,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"49decb","input":"About 80% of individuals in `cx_pop` should now be children with crossovers.  We'll print out the first 6 members of the population before and after crossover to see what happened.  If crossover occurred then the bottom part of each pair should stay the same while the top part of each pair gets swapped.  Compare the parents in the first set of columns to the children in the second set of columns.  You should be able to see where the top part of each pair children is swapped from the parents.","pos":55,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"4e295c","input":"The genetic algorithm does a good job of sifting through all of the local minima (there are $10^{10}$ local min for the 10-dimensional Rastrigin function), but it does a poor job of really zeroing in on the minimum.  For problems with continuous variables local search is usually combined with the genetic algorithm.","pos":69,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"538adb","input":"### Compute Fitness (again)\nWe'll copy `mut_pop` into the original population `pop` and evaluate the fitness before returning to the start of the loop.","pos":64,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"552ed1","input":"## Simulated Annealing for Continuous Optimization","metadata":{"heading_collapsed":true,"hidden":true},"pos":17,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"556862","input":"We found this two-dimensional example in <a href=\"http://apmonitor.com/me575/index.php/Main/SimulatedAnnealing\">this tutorial</a> on simulated annealing.\n\nFind the minimum value of \n$$f(x,y) = 0.2 + x^2 + y^2 - 0.1 \\cos(6 \\pi x) - 0.1 \\cos(6 \\pi y)$$ \n\nfor $-1 \\leq x,y \\leq 1$.  This function is similar to the Rastrigin function and the global minimum value is $f(0,0) = 0$.  A contour plot, shown below, illustrates that there are many local minima (in the center of many of the small loops, some correspond to local maxima).  The <a href = \"http://apmonitor.com/me575/index.php/Main/SimulatedAnnealing\">tutorial</a> itself is worthy of a look and has a nice flow chart outlining how simulated annealing works.","metadata":{"hidden":true},"pos":20,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"55bf61","input":"#### *Self-Assessment for Simulated Annealing with Continuous Variables*\n\nUse the objective and move functions from above to create a class using the `simanneal` package.  Use it to approximate the location of the global minimum for the \"Bumpy\" function above.  You'll notice that you usually will get close to the location of the global minimum at the origin, but it won't be exact because it is very difficult to randomly move exactly to the minimum location.  Usually, for continuous functions simulated annealing is combined with local search in an iterative procedure (we'll see an example of this in the homework with the `dual_annealing` optimizer from the `scipy.optimize` package.  For this example you could take the best state found by simulated annealing and use it to start a local search using `minimize` from `scipy.optimize` package.\n\nThe code from the TSP example above is a good starting point.  Instead of the distance matrix you'll need to pass the scale parameter sigma to determine the size of the moves.  A good starting point for sigma is range/6 where range = upper bound - lower bound.  This value for sigma is because a normal distribution is about 6 * sigma wide.  You may want to experiment with the value of sigma to see how it effects the result of simulated annealing.  You could also play with the time allowed when you set the schedule for the annealing.","pos":25,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"5f8cfb","input":"Think of a genetic algorithm as a smart version of random search.  Genetic algorithms are great at exploring large search spaces but sometimes aren't so good at zeroing in on a solution once they've gotten close to a good solution.\n\nYou should have read about the basics of genetic algorithms in the textbook.  Genetic algorithms are a vast subject and we'll just scratch the surface.  Fortunately there seem to be tons of free tutorials and other resources available for learning more about genetic algorithms.  The pseudocode for a genetic algorithm is as follows:\n```\ngenerate the initial population\ncompute fitness\nrepeat\n    selection\n    crossover\n    mutation\n    compute fitness\nuntil population has converged\n```\n\nHere are just a few notes about the algorithm:\n* population = set of trial solutions that are also called individuals (or chromosomes)\n* fitness = objective function\n* selection = choosing the most promising solutions in the current population but leaving a few bad ones for diversity\n* crossover = combining or breeding the selected solutions to generate new candidate solutions\n* mutation = randomly tweaking some of the solutions in the current population to encourage exploration of the solution space\n\nIn terms of the **exploration and exploitation tradeoff** one can think of selection as being exploitation (local search) and crossover and mutation as being exploration (global search).  Changing the parameters used in selection, crossover, and mutation changes the balance between exploration and exploitation.\n\n\nWe will write our own genetic algorithms so that we can get a better understanding of their ingredients.  Before we dive into the details we summarize some packages you could explore to apply genetic algorithms to your optimization problems.\n\n## Genetic Algorithm Packages\n\nIf you need to use genetic algorithms in practice, it's probably better to seak out a package that has that functionality.  Some options include:\n* <a href=\"https://github.com/deap/deap\" target=\"_blank\">The DEAP package</a>.  This package is for genetic programming.  It's very powerful and flexible, but also abstract with a significant learning curve.  It's worth learning if you often need to use genetic algorithms or other types of evolutionary algorithms.\n* <a href=\"https://pypi.org/project/geneticalgorithm/\" target=\"_blank\">The geneticalgorithm package</a> This package is an easy to use, but limited, genetic algorithm for minimization.  It supports either real or integer variables.  It can't be used for problems with permuations such as TSP.  Also the objective function can have only one argument so if you need additional data (e.g. the distance matrix) the function will have to find the data in the global scope.  It's slow with the default settings.\n* The `deap_wrapper` package.  This is something we've been working on but at the moment it's not a well documented package.  If you're curious you can see examples of how to use it in the notebook `deap_wrapper_examples.ipynb` in the same folder as this lesson.\n* The `GA` package in R.  This is a really easy to use implementation of the genetic algorithms that handles several types of variables.  Documentation is <a href=\"https://cran.r-project.org/web/packages/GA/\" target=\"_blank\">here on CRAN</a>.  In our experience this is a lot easier to use than DEAP.  The notebook `Genetic_Algorithm_with_R.ipynb` gives an example and shows how you can include R in a Python Jupyter notebook (it's pretty cool).","metadata":{"hidden":true},"pos":28,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"610187","input":"For mutation of permutation variables it is common to use Shuffling Indices.  To do just make a copy of the individual then loop over each variable and with probability `ind_prob` swap it with another randomly selected variable in the individual.  It's possible that you may end up swapping a variable with itself, but that's OK.\n\nTo initialize you'll to use a loop since it's only possible to create one random permutation at a time.\n\n**Example Initialization:**\n\nThe code below creates a population of ten sequences with values 0 to 7.","pos":75,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"6a9d11","input":"Simulated annealing was designed for combinatorial (discrete) optimization problems, but has been adapted to continuous optimization problems.  The main issue is how to generate a new move at each iteration.  There are many variations, but often the move is selected at random from a suitable probability distribution such as a normal or uniform distribution.\n\nThe objective functions we consider here aren't from real applications, instead they're chosen to give you an idea how the algorithm works for difficult optimization problems with many local optima.  It's good to have this sort of thing in mind when, for instance, you're trying to train a complicated neural network and have to optimize the weights in the network to find the best fit to your data.","metadata":{"hidden":true},"pos":18,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"6e1868","input":"# Simulated Annealing","metadata":{"heading_collapsed":true},"pos":2,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"74bee2","input":"Copy the gerrymandering code from Lesson 4 and adapt the genetic algorithm code above to try to find a solution in which republicans win 8 or 9 of the 10 districts.  Beware that you're trying to maximize the fitness.  The simplest way to use a minimization algorithm to maximize is to negate the fitness value.  If you start with simanneal_tsp then you should need only minor changes.\n\nTo make the genetic algorithm work, you'll need to pay attention to the following:\n* The initial population should be individuals of length 18 (`num_cities`) each having integer values between 0 and 9 with repeats allowed (there are `num_districts = 10` voting districts).  Use `numpy.random.randint`\n* You can use one-point crossover to mate individuals.  That part of the code doesn't need to change at al.  \n* For mutation you could change some of the district assignments in an individual randomly (use `ind_prob`).  Use `numpy.random.randint` to generate mutations for each variable.  The `move_one_district` function from Lesson 4 actually changes only one city so it isn't quite what we want here, but `fitness_districts` works just fine.\n* You may need to cast the population as integers before you evaluate the fitness function (or do it in the fitness function) using something like this:  `pop = pop.astype(int)`","metadata":{"hidden":true},"pos":79,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"761a68","input":"### Generate the Initial Population\nWe'll make our initial population have 50 individuals (sometimes called chromosomes)","pos":31,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"7679a0","input":"We'll add the \"repeat\" loop at the end when we put all of this together but first we'll apply each of the operators: selection, crossover, and mutation.\n\n### Selection\n\nWe want to select the fittest individuals from the population for breeding (crossover and mutation), but we also want to maintain diversity in the population so that breeding produces a variety of offspring to encourage exploration of the search space.\n\nWe'll implement tournament selection where we'll first choose a subset of individuals from the population and then select the fittest member of that subset for the new population.  The number of individuals in each subset is called the tournament size.  The larger the size of the tournament the more likely that only the fittest members of the population are selected for the next generation.  Small tournament sizes mean that less fit individuals have a chance to be selected.  We'll use a `tourn_size = 3`.  You can read a bit about other selection operators in any genetic algorithms textbook.  A small explanation about some selection operators can be found on <a href=\"https://en.wikipedia.org/wiki/Selection_(genetic_algorithm)#d._Tournament_Selection\">Wikipedia.</a>\n\nTo  facilitate selection we'll first sort the numpy array `pop` so that the individuals (columns) are ordered by increasing fitness.  Since we're minimizing the objective function the most fit individual will be in the first column and the least fit individual will be in the last column.  One way to do this sorting is to use `argsort()` which returns the positions of the sorted individuals in the original list.","pos":39,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"7bba20","input":"Now we'll apply argsort to the fitness values and use sort_pos to order both the fitness values and columns of the population:","pos":43,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"7cfb96","input":"***Note:  this is a new version of Lesson 5 that we wrote in Summer 2020.  Please fire away with questions on Piazza as we know the first draft of anything often needs clarification!***\n\n# Global Optimization\n\nThe goal of global optimization is to find the global optimimum value which means we want to identify the best possible soluiton in the entire search space.  However for many problems the search space is too large and/or the function landscape is too complicated to guarantee that the best solution can be found.\n\nA metaheuristic algorithm attempts to find a good solution without any guarantee of being able to find the best solution.  Often metaheuristics are stochastic in nature, that is they incorporate randomness as an element of the search, but they aren't generally completely random in nature.  They often incorporate search patterns which are known to work well for the problem at hand.\n\nMetaheuristic algorithms try to find a compromise somewhere between randomly searching the search space and local search.  People often speak of the **exploration and exploitation tradeoff**.  Exploration ensures the algorithm reaches different promising regions of the search space, whereas exploitation ensures the searching of optimal solutions within the given region.  The trick is in finding the right balance. Go too far into exploitation and the algorithm gets stuck in local extrema, go too far to exploration and the algorithm will waste time on solutions that are less likely to be good and ignore the information already gathered.\n\nUnfortunately there is no single algorithm which works best for all classes of problems.  This is often referred to as a \"no free lunch theorem\" in optimization.  We'll focus on the two stochastic optimization algorithms that are described in your textbook:  simulated annealing and genetic algorithms.","metadata":{"hidden":true},"pos":1,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"85b940","input":"We didn't actually need to save the fitness values for the selected individuals, but we did so that you can see the effect of selection.  If you look at the fitness values from the original population and the selected population fitness values you should notice that there are fewer large values and more small values in the selected population.  You may also see that there are repeats since it's likely that the fittest individuals are selected more than once.  That's selection in action:","pos":47,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"88cddd","input":"## Simulated Annealing with TSP (video)","metadata":{"hidden":true},"pos":4,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"8b68e3","input":"Let's print the first five columns to see what we have:","pos":33,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"910724","input":"### Compute Fitness\n\nWe want to apply the Rastrigin function to each individual or column in the numpy array `pop`. For a numpy array it's possible to do the computation in couple of lines without a loop, but that wouldn't generalize well to some of our other objective functions.  Instead we'll define our Rastrigin function and then use a loop to iterate over all the individuals in the population.","pos":35,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"925d40","input":"Think of simulated annealing as an enhanced local search that allows some moves that don't improve the best function value to try to climb\n\nIn a hill-climbing local search we only allow moves that increase the objective function value.  \n\nHere is our pseudo-code from the previous lesson for **Local Search:**\n```\n set starting state \n while local_condition \n     select a move \n     if acceptable \n         do the move \n         if new optimum \n             remember it \n endwhile \n ```\n\nSimulated annealing is a trajectory based method for generating a sequence of solutions and is similar our basic \"hill-climbing\" local search algorithm.  In a strict hill-climbing algorithm we only allow uphill moves, but in simulated move we sometimes allow downhill moves and are more likely to allow downhill moves in the early part of the search.  The idea is that to find the tallest peak in a mountain range we have to first descend from a lower peak.\n\nThe probability of a downhill move is determined by a temperature parameter that decreases throughout the search.  The probability of a downhill move depends on the size of the downhill move compared to the temperature.  At high temperatures large and small downhill moves are probable, but as the temperature decreases only small downhill moves are probable so that the search performs similarly to a local search at low temperatures\n\nIn simulated annealing algorithm high temperature promotes exploration (global search) while low temperature promote exploitation (local search).  As the algorithm proceeds the temperature decreases and transitions from exploration to exploitation.\n\nHere is pseudo-code for **Simulated Annealing:**\n```\n set starting state and initial temperature\n while local_condition \n     select a move \n     if acceptable \n         do the move \n         if new optimum or random # < probability determined by temperature\n             remember it\n     decrease temperature\n endwhile \n ```\n \nChoosing the initial temperature and the manner in which the temperature decreases are critical to the performance of simulated annealing.  We'll start with a temperature schedule that looks like this:\n$$ T = T_0 \\alpha^n.$$\nWhere $T_0$ is the initial temperature, $0 < \\alpha < 1,$ and $n$ is the number of iterations.   This is called geometric temperature decay, but many other choices are possible.  In the next section we'll demonstrate simulated annealing for the traveling salesman problem.\n\n\n\nIn the next section we present simulated annealing using our own code so that you can see how it works, but in general we'll use the `simanneal` package that will be introduced further below.","metadata":{"hidden":true},"pos":3,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"92def6","input":"### *Self-Assessment:  Crossover probability*\nWhat happens if `cx_prob = 0`?  What happens if `cx_prob=1`?","pos":58,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"94391b","input":"If everything is working well, then the fitness of the population should be generally be decreasing, but it's hard to tell if that is the case by looking at the fitness values from one iteration of the genetic algorithm.  Now we'll put it all together in a loop and track the best fitness found overall and in each generation.\n\n### Adjustable Parameters Overview\n\n<table >\n\t<tbody>\n\t\t<tr>\n            <td><b>parameter</b></td>\n            <td><b>variable name</b></td>\n            <td><b>lower bound</b></td>\n            <td><b>upper bound</b></td>\n            <td><b>typical value(s)</b></td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>population size</td>\n\t\t\t<td><code>pop_size</code></td>\n\t\t\t<td>2</td>\n\t\t\t<td>none</td>\n\t\t\t<td>number of variables * (5 to 20)</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>individual size</td>\n\t\t\t<td><code>ind_size</code></td>\n\t\t\t<td>NA</td>\n\t\t\t<td>NA</td>\n\t\t\t<td>always = number of variables</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>lower bound for real var.</td>\n\t\t\t<td><code>lower</code></td>\n\t\t\t<td>NA</td>\n\t\t\t<td>NA</td>\n\t\t\t<td>problem dependent</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>upper bound for real var. </td>\n\t\t\t<td><code>upper</code></td>\n\t\t\t<td>NA</td>\n\t\t\t<td>NA</td>\n\t\t\t<td>problem dependent</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>tournament size for selection</td>\n\t\t\t<td><code>tourn_size</code></td>\n\t\t\t<td>1</td>\n\t\t\t<td><code>pop_size</code></td>\n\t\t\t<td>3 to 5</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>crossover probability</td>\n\t\t\t<td><code>cx_prob</code></td>\n\t\t\t<td>0.0</td>\n\t\t\t<td>1.0</td>\n\t\t\t<td>0.8</td>\n\t\t</tr>\n        <tr>\n\t\t\t<td>mutation probability</td>\n\t\t\t<td><code>mut_prob</code></td>\n\t\t\t<td>0.0</td>\n\t\t\t<td>1.0</td>\n\t\t\t<td>0.2</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>single var. mutation prob.</td>\n\t\t\t<td><code>ind_prob</code></td>\n\t\t\t<td>0.0</td>\n\t\t\t<td>1.0</td>\n\t\t\t<td>0.05 to 0.1</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>real var. mutation size</td>\n\t\t\t<td><code>sigma</code> </td>\n\t\t\t<td>&#62 0.0</td>\n\t\t\t<td>none</td>\n\t\t\t<td>(upper-lower)/6</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>number of iterations</td>\n\t\t\t<td><code>num_iter</code></td>\n\t\t\t<td>1</td>\n\t\t\t<td>none</td>\n\t\t\t<td>problem dependent</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<td>update to screen interval</td>\n\t\t\t<td><code>update_iter</code></td>\n\t\t\t<td>1</td>\n\t\t\t<td><code>num_iter</code></td>\n\t\t\t<td><code>num_iter/20</code></td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n\n### Putting it Together\n\nFor our loop we'll just iterate a fixed number of times.  A more sophisticated genetic algorithm would monitor the convergence and use a dynamic stopping criteria.  Our implementation is not particularly efficient since the code was written for transparency and not efficiency ... this may be slow!\n\nThe goal for our genetic algorithm code is to increase your understanding of the genetic algorithm.  In truth, this is pretty lousy code if you're trying to use a genetic algorithms in a production setting. In practice it would be better to make the code modular by writing separate functions for each step and then having a master function to run the algorithm.  Or better still would be to use a package such as DEAP.\n\nThe video in the next cell gives an overview of the \"putting-it-together\" code:","pos":66,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"9dda44","input":"### Crossover (Mating)\n\nAt this point, the individuals in `select_pop` are in a random order after selection (if they weren't then we should shuffle them before continuing) so we're going to loop over pairs of individuals and with probability `cx_prob = 0.8` each pair will produce a pair of offspring using <a href=\"https://en.wikipedia.org/wiki/Crossover_(genetic_algorithm)\"> One Point Crossover </a> (<a href=\"https://en.wikipedia.org/wiki/Crossover_(genetic_algorithm)\">other kinds of crossover</a> are possible too) We randomly choose a \"crossover point\" and swap the two pieces of the two individuals.  The image below illustrates this nicely:\n\n<img src=\"./images/OnePointCrossover.png\" width=400>\n\nIn the next cell is a bit of Python that illustrates how One Point Crossover works when the crossover point is 3.","pos":51,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"9e8dfa","input":"### Mutation\n\nMany mutation operators are possible, but for real-valued variables such as those we are using to minimize the Rastrigin function, Gaussian Mutation is very common.  First we loop over the individuals in `cx_pop` and with probability `mut_prob` we mutate the individual.  If mutation occurs we loop over the `ind_size = 10` variables and with probability `ind_prob = 0.1` we add a random number from a normal distribution with mean 0 and standard deviation `sigma = 10.24/6`.  Just like when we used simulated_annealing above we choose sigma by fitting six standard deviations in the range of each variable from -5.12 to 5.12 (this is a guideline; smaller or larger mutations could be used).  Like we did with simulated annealing we'll also clip each mutated individual to stay inside the bounds.  Usually we'll set `mut_prob` to a value like 0.2, but we'll run it below with `mut_prob = 1.0` so we can see the mutations in some of the variables.","pos":59,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"a2d6cb","input":"The `simanneal` package is pretty straightforward to use. Using the simanneal package has a couple of advantages over our version of simulated annealing above.  First, we don't have to worry about the algorithm framework.  Second, we don't have to worry about figuring out a temperature schedule.  While it's possible to specify a temperature schedule, it is far easier to use the `auto` scheduler and specify the approximate amount of time we'd like to wait for a solution\n\nThe package works by making an object of the Annealer class and then calling the anneal method on that object. To set up a problem we have to set three things in our instance of the Annealer class.\n\n1.  the state initializer \n2.  the move function that tells the anneal how to generate new moves\n3.  the fitness function (fitness is called energy in this package and it was called objective in the locsearch package in Lesson 4).\n\nThe anneal method appears to always find minima so you may have to negate your function if you want to find a maximum. The <a href=\"https://github.com/perrygeo/simanneal\">Github page</a> has some short documentation about the simanneal package.\n\nThe next cell is walkthrough of the code below.","metadata":{"hidden":true},"pos":12,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"a80b2d","input":"We'll use the seven city example TSP from the textbook. Find the shortest tour (or cheapest cost) to visit all 7 cities and return to the starting city in the following graph:\n\n<img src=\"./images/HillierTSP.png\" width=400>\n\nWe'll store all of the intercity distances in a two dimensional list that we call distance_matrix. For cities that aren't connected we'll use the \"bigM\" method and introduce a distance of 100 between those pairs of cities so that those routes won't be included in the tour. Note that the picture labels the cities 1 through 7, but in Python we'll use 0 through 6.  The data is stored in the included json file.\n\nIf you want to really understand how simulated annealing worksThe following video includes a walkthrough of the code below.","metadata":{"hidden":true},"pos":5,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"aef838","input":"To use simulated annealing to optimize a function with continuous variables isn't all that different than how we used it to find a good, or even optimal, tour in the traveling salesman problem.  \n\nWe're going to rely on the `simanneal package` in the rest of this lesson because it's much more robust than our \"homebrewed\" code in the `simanneal_tsp()` function above. \nTo use the package we'll have to generate an initial state, define the `energy()` method for returning the objective function value, and define the `move()` method for making a move from a current state to a new state.\n\nTo generate an initial state you could select uniformly distributed random numbers between -1 and 1:\n```\ninit_state = np.random.uniform(low=-1, high=1, size=2)\n```\n\nWe like to write functions for computing the objective function value and for making moves and then call those functions from the `move()` and `energy()` methods in the class definition for our problem as we did in the simanneal package TSP example above.\n\nWe already have the objective function from where we made the contour plot:\n```\ndef f(xy):\n    obj = 0.2 + sum(xy**2 - 0.1*np.cos(6*np.pi*xy))\n    return obj\n```\n\nMaking a move will consist of applying two functions successively.  The first function adds normally distributed random numbers to each variable while the second function clips values that are out of the $[-1,1]$ bounds.  The scale of the move will need to be passed to the first function, while the values of the lower and upper bounds need to be passed to the clipping function.  These values will need to be initialized in the `__init__` constructor similar to how we worked with the distance matrix in the TSP example.  Here are the functions:\n```\ndef gauss_move(xy,sigma):\n    # xy is a 1 by dim numpy array\n    # sigma is the standard deviation for the normal distribution\n    dim = len(xy)\n    return xy + np.random.normal(loc = 0, scale = sigma, size=dim)\n\ndef clip_to_bounds(xy,low,high):\n    # xy is a 1 by dim numpy array\n    # low is the lower bound for clipping variables\n    # high is the upper bound for clipping variables\n    return np.array( [min(high,max(low,v)) for v in xy])\n```","metadata":{"hidden":true},"pos":24,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"b2a3c1","input":"To do tournament selection we'll randomly choose 3 integers between 0 and 49, say (3,27,38) and have a tournament between those three individuals.  Since the individual in column 3 is the fittest (in the sorted population) we'll select that individual.  Here is some code to do the tournament selection:","pos":45,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"bdf3bb","input":"#### *Self-Assessment:  Mutation Parameters:*\n\n* What is the effect of `mut_prob = 1`?\n* What is the effect of `mut_prob = 0`?\n* What is the effect of increasing `ind_prob`?\n* What would happen if you made `sigma` really large?\n* What would happen if you made `sigma` really small?","pos":63,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"c37884","input":"#### *Self-Assessment:  Exploring Tournament Selection*\n\nTry running the tournament selection code above with both smaller and larger tournament sizes.  What happens for smaller tournament sizes?  For larger tournament sizes?  For tournament size 1?  For tournament size the same as the population size?  How does tournament size impact selection?\n","pos":50,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"c431bb","input":"#### *Self-Assessment:  Refine the best solution with local search*\n\nRun the genetic algorithm on the Rastrigin function above until you're satisfied the output is near the global minimum.  Now take the location of the minimizer, `best_x`, and apply \n`minimize` from the `scipy.optimize` to get closer to the minimum value.  How does this approach compare to the multistart approach used on the 10-dimensional Rastrigin function in Lesson 4?  Which approach is more efficient?","pos":70,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"ccdd48","input":"### *Self Assessment: Simulated Annealing for Gerrymandering*","metadata":{"heading_collapsed":true,"hidden":true},"pos":9,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"d9deca","input":"### A non-convex 2D example","metadata":{"heading_collapsed":true,"hidden":true},"pos":19,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"e669a4","input":"The next cell contains code (also discussed in the video) that you can adapt to do Ordered Crossover in the homework.","pos":73,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"e814ed","input":"Here is some code to produce a new population from `select_pop` using One Point Crossover.","pos":53,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"e90c83","input":"Here is a 3D plot that makes it easier to see all of the local minima in the search space.  A local search will easily get stuck in the wrong minimum if the initial search point isn't very close to the origin.","pos":22,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"ebe6f3","input":"#### *Self-Assessment:  Genetic Algorithm for the Gerrymandering Problem*","pos":78,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"f187e8","input":"Use the `simanneal` package to try to find a solution in which republicans win 9 of the 10 districts.  Beware that you're trying to maximize the fitness so you'll either need to use a negated fitness function.  You'll also have to set the cities data frame in the initializer (similar to the distance matrix in the tsp above).  The set up here is very similar to using the `locsearch` package to solve the gerrymandering problem as we did in the last self-assessment in Lesson 4.\n\nIf you're using the auto option for the temperature schedule then it could take several minutes to complete a run because the search space for this problem is huge.  Each entry in the 18 dimensional vector can be a number 0 through 9 so there are $10^{18}$ possible vectors to explore.  Alternately you can manually set the temperature schedule with something like this:\n\n```\ntsp.Tmax = 5000\ntsp.Tmin = 2.5\ntsp.steps = 5000\ntsp.updates = 100\n```\n\nYou should replace tsp with the appropriate name that you setup in your code and also experiment with the numbers.  Make sure to comment out the auto schedule.  ","metadata":{"hidden":true},"pos":16,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"f57356","input":"### *Self Assessment: Simulated Annealing for Gerrymandering with `simanneal`*","metadata":{"hidden":true},"pos":15,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"fc016f","input":"# Genetic Algorithms","metadata":{"heading_collapsed":true},"pos":27,"state":"done","type":"cell"}
{"id":0,"time":1603497304069,"type":"user"}
{"last_load":1603551805943,"type":"file"}