{"backend_state":"init","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-96458585-e533-494c-83e9-ec7804ddeba4.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"234.363px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1610068073582,"exec_count":1,"id":"f8a408","input":"# EXECUTE FIRST\n\n# computational imports\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom surprise import Reader, Dataset, KNNBasic, SVD\n\nfrom ast import literal_eval\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\n\n# plotting imports\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n# for reading files from urls\nimport urllib.request\n# display imports\nfrom IPython.display import display, IFrame\nfrom IPython.core.display import HTML\n\n# import notebook styling for tables and width etc.\nresponse = urllib.request.urlopen('https://raw.githubusercontent.com/DataScienceUWL/DS775v2/master/ds755.css')\nHTML(response.read().decode(\"utf-8\"));","kernel":"python3","metadata":{"code_folding":[0]},"no_halt":true,"pos":0,"start":1610068068166,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068073626,"exec_count":2,"id":"8b8d82","input":"# import pandas as pd\n# import numpy as np\n\n#load the information about users\nusers = pd.DataFrame({'user_id': [1,2,3,4,5],\n                     'age': [24,53,23,20,55],\n                     'sex': ['M','F','M','F','M'],\n                     'occupation': ['technician', 'writer','teacher','technician','teacher'],\n                     'zip_code': ['90210', '53704', '53706','53704','90210']})\n\ndisplay(users.head())\n\nmovies = pd.DataFrame({'movie_id': [1,2,3,4,5],\n                      'title':['Toy Story','Titanic','Star Wars: The Clone Wars', 'Gone with the Wind', 'Sharknado']})\n\n\ndisplay(movies.head())\n\n#generate a rating for each user/movie combination\nratings = pd.DataFrame(np.array(np.meshgrid([1, 2, 3,4,5], [1,2,3,4,5])).T.reshape(-1,2), columns=['user_id', 'movie_id'])\nnp.random.seed(1)\nrandratings = np.random.randint(1,6, ratings.shape[0])\n\nratings['rating'] = randratings\n\n#we have 5 * 5 or 25 rows of data in the ratings, but we'll just look at the first 10\nratings.head(10)","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>age</th>\n      <th>sex</th>\n      <th>occupation</th>\n      <th>zip_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>90210</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>53</td>\n      <td>F</td>\n      <td>writer</td>\n      <td>53704</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>23</td>\n      <td>M</td>\n      <td>teacher</td>\n      <td>53706</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>20</td>\n      <td>F</td>\n      <td>technician</td>\n      <td>53704</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>55</td>\n      <td>M</td>\n      <td>teacher</td>\n      <td>90210</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   user_id  age sex  occupation zip_code\n0        1   24   M  technician    90210\n1        2   53   F      writer    53704\n2        3   23   M     teacher    53706\n3        4   20   F  technician    53704\n4        5   55   M     teacher    90210"}},"1":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Titanic</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Star Wars: The Clone Wars</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Gone with the Wind</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Sharknado</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   movie_id                      title\n0         1                  Toy Story\n1         2                    Titanic\n2         3  Star Wars: The Clone Wars\n3         4         Gone with the Wind\n4         5                  Sharknado"}},"2":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   user_id  movie_id  rating\n0        1         1       4\n1        1         2       5\n2        1         3       1\n3        1         4       2\n4        1         5       4\n5        2         1       1\n6        2         2       1\n7        2         3       2\n8        2         4       5\n9        2         5       5"},"exec_count":2}},"pos":4,"start":1610068073600,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068073655,"exec_count":3,"id":"6c231a","input":"#Import the train_test_split function\n# from sklearn.model_selection import train_test_split\n\n#Assign X as the original ratings dataframe and y as the user_id column of ratings.\nX = ratings.copy()\ny = ratings['user_id']\n\n#Split into training and test datasets, stratified along user_id\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify=y, random_state=42)","kernel":"python3","no_halt":true,"pos":6,"start":1610068073634,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068073748,"exec_count":4,"id":"c0534e","input":"#compare X_train to X_test\ndisplay(X_train)\ndisplay(X_test)","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>5</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>4</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>5</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>3</td>\n      <td>3</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>5</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"    user_id  movie_id  rating\n1         1         2       5\n20        5         1       5\n22        5         3       2\n8         2         4       5\n5         2         1       1\n17        4         3       3\n24        5         5       2\n10        3         1       2\n6         2         2       1\n9         2         5       5\n2         1         3       1\n12        3         3       5\n18        4         4       5\n13        3         4       3\n3         1         4       2\n11        3         2       3\n23        5         4       1\n15        4         1       4"}},"1":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>movie_id</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16</th>\n      <td>4</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>4</td>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>5</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>3</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"    user_id  movie_id  rating\n16        4         2       5\n7         2         3       2\n19        4         5       3\n21        5         2       2\n14        3         5       5\n4         1         5       4\n0         1         1       4"}}},"pos":8,"start":1610068073661,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068073804,"exec_count":5,"id":"27dd86","input":"#Import the mean_squared_error function\n# from sklearn.metrics import mean_squared_error\n\n#test data\ntest_y_true = [3, -0.5, 2, 7]\ntest_y_pred = [2.5, 0.0, 2, 8]\n\n#this returns MSE (not what we want)\nprint(mean_squared_error(test_y_true, test_y_pred))\n\n#this returns the root mean squared error (and is what we want to use)\nmean_squared_error(test_y_true, test_y_pred, squared=False)","kernel":"python3","no_halt":true,"output":{"0":{"name":"stdout","text":"0.375\n"},"1":{"data":{"text/plain":"0.6123724356957945"},"exec_count":5}},"pos":11,"start":1610068073755,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068073829,"exec_count":6,"id":"990846","input":"#first determine the median of our ratings (we could have done this by hand, but numpy does it so well... )\nprint(f\"The median of this rating range is {np.median(np.arange(np.min(ratings['rating']), (np.max(ratings['rating']) + 1)))}\")\n\n#define a baseline model to always return the median\ndef baseline(user_id, movie_id, *args):\n    return 3.0","kernel":"python3","no_halt":true,"output":{"0":{"name":"stdout","text":"The median of this rating range is 3.0\n"}},"pos":13,"start":1610068073810,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068073896,"exec_count":7,"id":"eea916","input":"#Function to compute the RMSE score obtained on the testing set by a model\ndef score(cf_model, X_test, *args):\n    \n    #Construct a list of user-movie tuples from the testing dataset\n    id_pairs = zip(X_test['user_id'], X_test['movie_id'])\n    \n    #Predict the rating for every user-movie tuple\n    y_pred = np.array([cf_model(user, movie, *args) for (user, movie) in id_pairs])\n    \n    #Extract the actual ratings given by the users in the test data\n    y_true = np.array(X_test['rating'])\n    \n    #Return the final RMSE score\n    return mean_squared_error(y_true, y_pred, squared=False)\n                              \n#let's test it with our baseline model\nscore(baseline, X_test)","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/plain":"1.3093073414159542"},"exec_count":7}},"pos":15,"start":1610068073835,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068074159,"exec_count":8,"id":"7c2b3e","input":"#Build the ratings matrix using pivot_table function\nr_matrix = X_train.pivot_table(values='rating', index='user_id', columns='movie_id')\n\nr_matrix.head()","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>movie_id</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"movie_id    1    2    3    4    5\nuser_id                          \n1         NaN  5.0  1.0  2.0  NaN\n2         1.0  1.0  NaN  5.0  5.0\n3         2.0  3.0  5.0  3.0  NaN\n4         4.0  NaN  3.0  5.0  NaN\n5         5.0  NaN  2.0  1.0  2.0"},"exec_count":8}},"pos":18,"start":1610068073908,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068074223,"exec_count":9,"id":"f80ccb","input":"#User Based Collaborative Filter using Mean Ratings\ndef cf_user_mean(user_id, movie_id, ratings_matrix):\n    \n    #Check if movie_id exists in r_matrix (rm)\n    if movie_id in ratings_matrix:\n        #Compute the mean of all the ratings given to the movie\n        mean_rating = ratings_matrix[movie_id].mean()\n    \n    else:\n        #Default to a rating of 3.0 in the absence of any information\n        mean_rating = 3.0\n    \n    return mean_rating\n\nscore(cf_user_mean, X_test, r_matrix)","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/plain":"1.153411090139653"},"exec_count":9}},"pos":21,"start":1610068074167,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068074312,"exec_count":10,"id":"681c5c","input":"#Create a dummy ratings matrix with all null values imputed to 0\nr_matrix_dummy = r_matrix.copy().fillna(0)\n# Import cosine_score \n# from sklearn.metrics.pairwise import cosine_similarity\n\n#Compute the cosine similarity matrix using the dummy ratings matrix\ncosine_sim = cosine_similarity(r_matrix_dummy, r_matrix_dummy)\n\n#Convert into pandas dataframe \ncosine_sim = pd.DataFrame(cosine_sim, index=r_matrix.index, columns=r_matrix.index)\n\ncosine_sim.head(10)","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>user_id</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>0.379777</td>\n      <td>0.692411</td>\n      <td>0.335659</td>\n      <td>0.125245</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.379777</td>\n      <td>1.000000</td>\n      <td>0.404557</td>\n      <td>0.568737</td>\n      <td>0.475651</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.692411</td>\n      <td>0.404557</td>\n      <td>1.000000</td>\n      <td>0.783880</td>\n      <td>0.575360</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.335659</td>\n      <td>0.568737</td>\n      <td>0.783880</td>\n      <td>1.000000</td>\n      <td>0.751860</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.125245</td>\n      <td>0.475651</td>\n      <td>0.575360</td>\n      <td>0.751860</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"user_id         1         2         3         4         5\nuser_id                                                  \n1        1.000000  0.379777  0.692411  0.335659  0.125245\n2        0.379777  1.000000  0.404557  0.568737  0.475651\n3        0.692411  0.404557  1.000000  0.783880  0.575360\n4        0.335659  0.568737  0.783880  1.000000  0.751860\n5        0.125245  0.475651  0.575360  0.751860  1.000000"},"exec_count":10}},"pos":23,"start":1610068074230,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068074645,"exec_count":11,"id":"31f206","input":"#User Based Collaborative Filter using Weighted Mean Ratings\ndef cf_user_wmean(user_id, movie_id, ratings_matrix, c_sim_matrix):\n    \n    #Check if movie_id exists in r_matrix\n    if movie_id in ratings_matrix:\n        \n        #Get the similarity scores for the user in question with every other user\n        sim_scores = c_sim_matrix[user_id]\n        \n        #Get the user ratings for the movie in question\n        m_ratings = ratings_matrix[movie_id]\n        \n        #Extract the indices containing NaN in the m_ratings series\n        idx = m_ratings[m_ratings.isnull()].index\n        \n        #Drop the NaN values from the m_ratings Series\n        m_ratings = m_ratings.dropna()\n        \n        #Drop the corresponding cosine scores from the sim_scores series\n        sim_scores = sim_scores.drop(idx)\n        \n        #Compute the final weighted mean\n        wmean_rating = np.dot(sim_scores, m_ratings)/ sim_scores.sum()\n\n    else:\n        #Default to a rating of 3.0 in the absence of any information\n        wmean_rating = 3.0\n    \n    return wmean_rating\n\n\n\nscore(cf_user_wmean, X_test, r_matrix, cosine_sim)","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/plain":"1.2892045169426134"},"exec_count":11}},"pos":25,"start":1610068074321,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068074848,"exec_count":12,"id":"1304ff","input":"#merge the training set with the user data\nmerged_df = pd.merge(X_train, users.copy())\n\n#Compute the mean rating of every movie by gender\ngender_mean = merged_df[['movie_id', 'sex', 'rating']].copy().groupby(['movie_id', 'sex'])['rating'].mean()\n\ndisplay(gender_mean.head())\n\n#Set the index of the users dataframe to the user_id\n#we need to do this so that we can fetch the right data in our model function\nusers = users.set_index('user_id')\n\ndisplay(users)","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/plain":"movie_id  sex\n1         F      2.5\n          M      3.5\n2         F      1.0\n          M      4.0\n3         F      3.0\nName: rating, dtype: float64"}},"1":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>occupation</th>\n      <th>zip_code</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>24</td>\n      <td>M</td>\n      <td>technician</td>\n      <td>90210</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>53</td>\n      <td>F</td>\n      <td>writer</td>\n      <td>53704</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23</td>\n      <td>M</td>\n      <td>teacher</td>\n      <td>53706</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20</td>\n      <td>F</td>\n      <td>technician</td>\n      <td>53704</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>55</td>\n      <td>M</td>\n      <td>teacher</td>\n      <td>90210</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"         age sex  occupation zip_code\nuser_id                              \n1         24   M  technician    90210\n2         53   F      writer    53704\n3         23   M     teacher    53706\n4         20   F  technician    53704\n5         55   M     teacher    90210"}}},"pos":28,"start":1610068074656,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068075004,"exec_count":13,"id":"0ad2c7","input":" #Gender Based Collaborative Filter using Mean Ratings\ndef cf_gender(user_id, movie_id, ratings_matrix, user_df, gen_mean):\n    \n    #Check if movie_id exists in r_matrix (or training set)\n    if movie_id in ratings_matrix:\n        #Identify the gender of the user\n        gender = user_df.loc[user_id]['sex']\n        \n        #Check if the gender has rated the movie\n        if gender in gen_mean[movie_id]:\n            \n            #Compute the mean rating given by that gender to the movie\n            gender_rating = gen_mean[movie_id][gender]\n        \n        else:\n            gender_rating = 3.0\n    \n    else:\n        #Default to a rating of 3.0 in the absence of any information\n        gender_rating = 3.0\n    \n    return gender_rating\n\nscore(cf_gender,  X_test, r_matrix, users, gender_mean)","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/plain":"2.3375811674219387"},"exec_count":13}},"pos":30,"start":1610068074855,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068075188,"exec_count":14,"id":"b26064","input":"#Compute the mean rating by gender and occupation\ngen_occ_mean = merged_df[['sex', 'rating', 'movie_id', 'occupation']].pivot_table(\n    values='rating', index='movie_id', columns=['occupation', 'sex'], aggfunc='mean')\n\ngen_occ_mean.head()\n\n#Gender and Occupation Based Collaborative Filter using Mean Ratings\ndef cf_gen_occ(user_id, movie_id, user_df, gen_occ_mean_df):\n    \n    #Check if movie_id exists in gen_occ_mean\n    if movie_id in gen_occ_mean_df.index:\n        \n        #Identify the user\n        user = user_df.loc[user_id]\n        \n        #Identify the gender and occupation\n        gender = user['sex']\n        occ = user['occupation']\n        \n        #Check if the occupation has rated the movie\n        if occ in gen_occ_mean_df.loc[movie_id]:\n            \n            #Check if the gender has rated the movie\n            if gender in gen_occ_mean_df.loc[movie_id][occ]:\n                \n                #Extract the required rating\n                rating = gen_occ_mean_df.loc[movie_id][occ][gender]\n                \n                #Default to 3.0 if the rating is null\n                if np.isnan(rating):\n                    rating = 3.0\n                \n                return rating\n            \n    #Return the default rating    \n    return 3.0\n\n#compute the RMSE\nscore(cf_gen_occ,  X_test, users, gender_mean)","kernel":"python3","no_halt":true,"output":{"0":{"data":{"text/plain":"1.3093073414159542"},"exec_count":14}},"pos":32,"start":1610068075020,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068075376,"exec_count":15,"id":"6963db","input":"# this has been edited - replace \"evaluate\" with \"cross_validate\"\n\n#Import the required classes and methods from the surprise library\n# from surprise import Reader, Dataset, KNNBasic\n\n#Define a Reader object\n#The Reader object helps in parsing the file or dataframe containing ratings\nreader = Reader(rating_scale=(1,5)) # defaults to (0,5)\n\n#Create the dataset to be used for building the filter\ndata = Dataset.load_from_df(ratings, reader)\n\n#define a random seed for consistent results\nnp.random.seed(1)\n#Define the algorithm object; in this case kNN\nknn = KNNBasic(k=3, verbose=False) #the default for k is 40, we're also setting verbose to False to supress messages\n\n#This code cross validates (evaluates) the model\nfrom surprise.model_selection import cross_validate\nknn_cv = cross_validate(knn, data, measures=['RMSE'], cv=5, verbose=True)\nprint(knn_cv)\n\n#to extract the mean RMSE, we need to get the mean of the test_rmse values\nknn_RMSE = np.mean(knn_cv['test_rmse'])\nprint(f'\\nThe RMSE across five folds was {knn_RMSE}')","kernel":"python3","no_halt":true,"output":{"0":{"name":"stdout","text":"Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    1.6963  1.7883  1.7354  2.2908  3.0011  2.1024  0.4983  \nFit time          0.00    0.00    0.00    0.00    0.00    0.00    0.00    \nTest time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n{'test_rmse': array([1.6963266 , 1.7882953 , 1.73543669, 2.29079882, 3.00109583]), 'fit_time': (7.295608520507812e-05, 2.9087066650390625e-05, 2.5987625122070312e-05, 0.00010418891906738281, 3.695487976074219e-05), 'test_time': (0.00011134147644042969, 6.723403930664062e-05, 5.7220458984375e-05, 9.131431579589844e-05, 0.00010251998901367188)}\n\nThe RMSE across five folds was 2.10239064827985\n"}},"pos":37,"start":1610068075194,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068075531,"exec_count":16,"id":"0a2117","input":"# this has been edited - replace \"evaluate\" with \"cross_validate\"\n#Import SVD\n# from surprise import SVD\n\n#define a random seed for consistent results\nnp.random.seed(1)\n#Define the SVD algorithm object\nsvd = SVD()\n\n#Evaluate the performance in terms of RMSE\nsvd_cv = cross_validate(svd, data, measures=['RMSE'], cv=5, verbose=True)\n#to extract the mean RMSE, we need to get the mean of the test_rmse values\nsvd_RMSE = np.mean(svd_cv['test_rmse'])\nprint(f'\\nThe RMSE across five folds was {svd_RMSE}')","kernel":"python3","no_halt":true,"output":{"0":{"name":"stdout","text":"Evaluating RMSE of algorithm SVD on 5 split(s).\n\n                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \nRMSE (testset)    1.1140  1.5535  1.8721  1.5735  1.8817  1.5990  0.2802  \nFit time          0.00    0.00    0.00    0.00    0.00    0.00    0.00    \nTest time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n\nThe RMSE across five folds was 1.5989842066442819\n"}},"pos":40,"start":1610068075382,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068075641,"exec_count":17,"id":"da8c25","input":"# load the data\nimport pandas as pd\nbx = pd.read_csv('./data/BX-Book-Ratings-3000.csv')","kernel":"python3","no_halt":true,"pos":45,"start":1610068075535,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068075755,"exec_count":18,"id":"35bca7","input":"# enter your code here","kernel":"python3","no_halt":true,"pos":46,"start":1610068075647,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068076034,"exec_count":19,"id":"60d04d","input":"# enter your code here","kernel":"python3","no_halt":true,"pos":49,"start":1610068075775,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068076072,"exec_count":20,"id":"099006","input":"# enter your code here","kernel":"python3","no_halt":true,"pos":52,"start":1610068076040,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068076109,"exec_count":21,"id":"5f4713","input":"# enter your code here","kernel":"python3","no_halt":true,"pos":55,"start":1610068076079,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068076202,"exec_count":22,"id":"00493c","input":"# enter your code here","kernel":"python3","no_halt":true,"pos":58,"start":1610068076116,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068076276,"exec_count":23,"id":"adae6e","input":"# enter your code here","kernel":"python3","no_halt":true,"pos":61,"start":1610068076211,"state":"done","type":"cell"}
{"cell_type":"code","end":1610068076377,"exec_count":24,"id":"afdf6d","input":"# enter your code here","kernel":"python3","no_halt":true,"pos":64,"start":1610068076286,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"03191c","input":"### RMSE Metric\n\nOur metric for evaluation will be the Root Mean Squared Error. Banik builds a wrapper function around scikit-learn's mean_squared_error function, but that's unnecessary as of scikit-learn version 0.22.1. The function has a parameter we can use to tell it to return the RMSE instead of the MSE.","pos":10,"type":"cell"}
{"cell_type":"markdown","id":"04f336","input":"### Mean","pos":19,"type":"cell"}
{"cell_type":"markdown","id":"068370","input":"With the cosine similarity matrix in hand, we can set up the weighted mean function. This function needs 2 additional arguments - the rating_matrix and the cosine similarity matrix (c_sim_matrix).","pos":24,"type":"cell"}
{"cell_type":"markdown","id":"092ba8","input":"### *Self-Assessment: kNN-Based Collaborative Filter*","pos":56,"type":"cell"}
{"cell_type":"markdown","id":"09f6d9","input":"With the data loaded, our job is to predict the rating, given a user and a movie. We will do this as a regression problem, even though the ratings could be considered categorical data (discrete values from 1 to 5), because a 4 is closer to a 5. Classification problems don't understand that nuance.\n\nLet's split the data into train and test sets. Banik uses a hack here to stratify on the user. Stratifying on the user ensures that we have some of each user's ratings in both the train and the test set. ","pos":5,"type":"cell"}
{"cell_type":"markdown","id":"0d205f","input":"Use the *surprise* library in Python to build an kNN-based collaborative filtering model for the BX-Books ratings.  Fit the model on the full data set (this is what we did in the examples) and compute the average RMSE for this model from 5 cross-validations. Compare it to the RMSEs of the baseline, weighted mean user-based, and weighted mean item-based models previously obtained.\n\n\n","pos":57,"type":"cell"}
{"cell_type":"markdown","id":"1001fd","input":"Create a recommender system that is a hybrid of an item-based collaborative filter and the SVD collaborative filter.  \nYour recommender should do the following:\n\n* Take in a user ID and book title, the cosine similarity matrix, the item data and the trained predictor algorithm as user input\n* Use cosine similarity among books to find the 25 most similar books\n* Compute the predicted ratings that the user might give to these 25 books using the SVD collaborative filter\n\nReturn the top 10 book recommendations along with their predicted ratings when user **31315** enters the book with ISBN **440214041**.  \n\nUse the entire data set to build this model (*i.e.* don't split into training and testing sets). This is what we did in the examples.","pos":63,"type":"cell"}
{"cell_type":"markdown","id":"107640","input":"### Weighted Mean\nWeighted mean is going to give more weight to the users that are more similar to each other. We'll do this using cosine similarity.","pos":22,"type":"cell"}
{"cell_type":"markdown","id":"1b2642","input":"Use the *surprise* library in Python to build a filtering model based on singular-value decomposition (SVD).  Fit the model on the full data set and compute the average RMSE for this model from 5 cross-validations and compare it to the RMSEs of the previous models.","pos":60,"type":"cell"}
{"cell_type":"markdown","id":"27de09","input":"All of the above models were relatively simple and straightforward calculations. Machine learning algorithms can give us a more powerful approach. We'll look a couple of options.","pos":34,"type":"cell"}
{"cell_type":"markdown","id":"339a80","input":"A user-based collaborative filter is one in which the preferences of users are used to identify suitable recommendations. For example, if Jaunita and Jeff largely like the same movies, but Jaunita liked Toy Story and Jeff hasn't seen it yet, then Toy Story might be a suitable recommendation for Jeff.\n\nBe sure to carefully read Chapter 5 before starting this lesson. \n\n## Set Up\n\n### Defining Data\nIn Chapter 6, Banik uses the movielens dataset to explore collaborative filtering. We're going to use what's called a \"toy\" dataset, which is just a very small dataset. This makes it easier to see what's happening at each step, though our predictions will be worse because we have much less data to go on.\n","pos":3,"type":"cell"}
{"cell_type":"markdown","id":"3e40cd","input":"# One More Self-Assessment","pos":65,"type":"cell"}
{"cell_type":"markdown","id":"3f0527","input":"### *Self-Assessment: Weighted Mean Item-Based Filter*","pos":53,"type":"cell"}
{"cell_type":"markdown","id":"46c3ab","input":"Build a ratings matrix from the data frame of users, books, and ratings and build a user-based collaborative filtering model that weights mean rank using cosine similarity among users.  Fit the model on the training set and compute the RMSE for this model using the test set and compare it to the RMSE of the baseline model.  Is it better than baseline?  (*i.e.* is the RMSE smaller?)","pos":51,"type":"cell"}
{"cell_type":"markdown","id":"537587","input":"# User-Based Collaborative Filter","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"53948b","input":"The file **BX-Book-Ratings-3000.csv** (found in the presentation download for this lesson) is loaded here for you, though you may need to change the file path unless you create the same folder structure. Note that book ratings have been adjusted so the scale goes from 1 to 11.   \n\nRun the cell below it to load the file and then do the following:\n\n* display the first 5 lines of the data (get familiar with the data frame)\n* calculate the mean book rating for all books (just to get an idea)\n* split the data set so that 70\\% of a users ratings are in the training set and 30\\% are in the testing set","pos":44,"type":"cell"}
{"cell_type":"markdown","id":"54d607","input":"## Basic Models\n","pos":16,"type":"cell"}
{"cell_type":"markdown","id":"7b6b23","input":"When we looked at demographics, we were using hard-coded data to determine what makes people \"similar\" and assuming that if they were similar in that respect, their taste in movies would also be similar. But that might be a faulty assumption. \n\nK Nearest Neighbors, on the other hand, can train the data on how users have actually rated movies. Perhaps there are clusters of individuals that rate movies in similar ways. K Nearest neighbors will try to find these clusters.\n\nSpecifically, what this algorithm does is:\n- Find the k-nearest neighbors that have rated movie m\n- Outputs the average rating of the k users for the movie m\n\nThe <a href=\"https://surprise.readthedocs.io/en/stable/knn_inspired.html\">documentation for KNNBasic</a> goes over all the parameters you can set when you're setting up the algorithm.\n\nNote that in this toy set, since we only have a handful of neighbors, we will need to decrease the number of neighbors (k) that the algorithm takes into consideration. Otherwise, we'll just be getting the mean of all the considered ratings in each fold.","pos":36,"type":"cell"}
{"cell_type":"markdown","id":"80a4c5","input":"### *Self-Assessment: SVD Filter*","pos":59,"type":"cell"}
{"cell_type":"markdown","id":"81bcdd","input":"Match the type of recommender system with its brief description by matching the letter of the recommender system with the number of the description.\n\n**Recommenders**\n\na. simple \n\nb. knowledge-based\n\nc. content-based\n\nd. user-based collaborative filters \n\ne. item-based collaborative filters  \n\nf. hybrid \n\n\n**Descriptions**\n\n1.  This model provides recommendations based on items with similar descriptions and features that match the profile of the user.\n\n\n2. Uses similarity among items to to create an ordered list of recommended items based on metric of interest (*i.e.* ratings).\n\n\n3. Recommendations made to users are based on an ordered list of items that are ranked according to some metric of interest (*i.e.* ratings).\n\n\n4. A combination of recommender systems that makes use of the advantages of each system used.\n\n\n5. Items are recommended that meet the specifics and preferences elicited from users and are ranked according to  metric of interest (*i.e.* ratings).\n\n\n6.  Uses similarity among users to create an ordered list of recommended items based on metric of interest (*i.e.* ratings).\n\n\n**Put the letter of the recommender system with the number of its description.**\n\n1.\n\n2.\n\n3.\n \n4.\n\n5.\n\n6.\n","pos":67,"type":"cell"}
{"cell_type":"markdown","id":"87c900","input":"Next we need a way to score our model.\n\nHere's where we diverge from Banik's approach just a bit. Instead of relying on global variables, we will explicitly pass in our data for our scoring model. Note we're again using the special parameter \\*args. This tells our scoring function to accept any optional arguments we might need, and we'll pass those right along to our model.\n\nWe'll also use sklearn's built in RMSE function.","pos":14,"type":"cell"}
{"cell_type":"markdown","id":"88dd7b","input":"Since we have such a small dataset, we can explore what's in our training and test data. You can see that every user is in both the training and test data, though not in equal measure.\n","pos":7,"type":"cell"}
{"cell_type":"markdown","id":"8bcfec","input":"We can also combine multiple demographic variables. Let's combine gender and occupation. Note that for this function, we're actually passing in the rating with the gender/occupation dataframe, which is a slightly different approach than the gender only model.","pos":31,"type":"cell"}
{"cell_type":"markdown","id":"8cfb1f","input":"Let's define a baseline model. All our models will take in a user_id and a movie_id. The baseline model always returns the MEDIAN of our possible ratings. In other words, our baseline model is trying to be as non-commital as possible.\n\nWe're going to alter Banik's function so that it also accepts optional arguments. We don't need any for this function, but later we will need additional arguments and this keeps our coding consistent.","pos":12,"type":"cell"}
{"cell_type":"markdown","id":"943a18","input":"The general idea here is that users with the same demographics might have similar tastes. (Note that with our toy dataset, since we used random number generation for our ratings, it's unlikely there's any actual correlation between demographics and taste. But we'll step through this anyway.)","pos":27,"type":"cell"}
{"cell_type":"markdown","id":"99187b","input":"### *Self-Assessment: Setting up the File*","pos":43,"type":"cell"}
{"cell_type":"markdown","id":"9adceb","input":"### *Self-Assessment: Hybrid Recommender*","pos":62,"type":"cell"}
{"cell_type":"markdown","id":"a54594","input":"### K Nearest Neighbors","pos":35,"type":"cell"}
{"cell_type":"markdown","id":"aa5cd2","input":"### Singular-value Decomposition (SVD)","pos":38,"type":"cell"}
{"cell_type":"markdown","id":"ae6087","input":"### *Self-Assessment: Type of Recommenders*","pos":66,"type":"cell"}
{"cell_type":"markdown","id":"ba3dfe","input":"Create a new ratings matrix from the data frame of users, books, and ratings with the rows defined by books (*i.e.* items) and columns defined by users to build an item-based collaborative filtering model that weights mean rank using cosine similarity among items.  Fit the model on the training set and compute the RMSE for this model on the test and compare it to the RMSEs of the baseline and weighted mean user-based models.  Is this one better than baseline?","pos":54,"type":"cell"}
{"cell_type":"markdown","id":"be34ba","input":"Build a baseline model that assigns a neutral rating and compute the RMSE of these simple \"predictions\" using the testing set. Make sure to make this model accept \\*args so that it aligns with more complicated models.\n\nA neutral rating would occur at the midpoint of the rating scale.  Calculate the median of the rating scale to determine what the baseline model should return.","pos":48,"type":"cell"}
{"cell_type":"markdown","id":"c6efc2","input":"### User Demographics","pos":26,"type":"cell"}
{"cell_type":"markdown","id":"c7c9f6","input":"<font size=18>Lesson 11: Recommender Systems 2</font>","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"c96d76","input":"# Self Assessment\nFollow the examples and use the code files provided from from chapters 5-7 in **Hands-On Recommendation Systems with Python** by Rounak Banik to do the following self-assessment exercises.  \n\nThe self-assessments in this lesson will be using a subset of data from the Book-Crossing dataset.  Click <a href = http://www2.informatik.uni-freiburg.de/~cziegler/BX/> here </a> for more details on the Book-Crossing dataset.","pos":41,"type":"cell"}
{"cell_type":"markdown","id":"cb046f","input":"Everything we've done so far is just setting us up to be able to use something more than our baseline model to do some real user-based collaborative filtering. Now let's try out some basic approaches and compare them to our baseline model.\n\nBefore we can start, though, we need to do yet more data wrangling. We need a matrix that has movies as columns and users as rows, with each user's rating for that movie at the intersection. Note that although we know that every user has rated every movie, we don't have all that data in our training set, so we still end up with some NaN values.","pos":17,"type":"cell"}
{"cell_type":"markdown","id":"cea0ec","input":"The theory behind SVD is covered in Banik's book. The very high-level concept is that it's a method that allows you to reduce the dimensions of a sparse matrix and \"fill in the blanks\" with predictions. We don't expect you to understand the intricacies. The code itself is extremely simple, once you've already got a suprise data object set up. Read the <a href=\"https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD\">full documentation</a> if you're curious.","pos":39,"type":"cell"}
{"cell_type":"markdown","id":"d01cd7","input":"## User-Based Collaborative Filter","pos":42,"type":"cell"}
{"cell_type":"markdown","id":"d42fbf","input":"### *Self-Assessment: Baseline RMSE to Assess Model Performance*","pos":47,"type":"cell"}
{"cell_type":"markdown","id":"da5213","input":"### *Self-Assessment: Weighted Mean User-Based Filter*","pos":50,"type":"cell"}
{"cell_type":"markdown","id":"e4969d","input":"Once again we're going to modify Banik's function to compute the gender-influenced score. This one needs to take in our results matrix (ratings_matrix), our user dataframe (user_df) and our gender mean data (gen_mean).","pos":29,"type":"cell"}
{"cell_type":"markdown","id":"e87d7b","input":"## Model Based Approaches","pos":33,"type":"cell"}
{"cell_type":"markdown","id":"ea5822","input":"Note that our mean function requires the ratings_matrix argument. Here's where that \\*args parameter comes in. We can pass r_matrix to our score function and it gets passed along to our cf_user_mean model.","pos":20,"type":"cell"}
{"cell_type":"markdown","id":"fdc12a","input":"The variables y_train and y_test won't actually be used in our code. They're just used as a way to stratify the data. Typically you'd see y as the variable you're trying to predict. That's not how we're doing it here, since our X_train and X_test data are actually dataframes that contain both what we're using to make predictions (user_id and movie_id combination) and what we're predicting (rating). (It's a bit weird. We know.)","pos":9,"type":"cell"}
{"id":0,"time":1611005218561,"type":"user"}
{"last_load":1610067726543,"type":"file"}